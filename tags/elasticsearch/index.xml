<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elasticsearch on 峰峰的博客</title><link>https://zhaoyifengf.github.io/tags/elasticsearch/</link><description>Recent content in Elasticsearch on 峰峰的博客</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>峰峰</copyright><lastBuildDate>Mon, 10 Feb 2025 22:34:00 +0800</lastBuildDate><atom:link href="https://zhaoyifengf.github.io/tags/elasticsearch/index.xml" rel="self" type="application/rss+xml"/><item><title>ES Introduction</title><link>https://zhaoyifengf.github.io/p/es-introduction/</link><pubDate>Mon, 10 Feb 2025 22:34:00 +0800</pubDate><guid>https://zhaoyifengf.github.io/p/es-introduction/</guid><description>&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/cover.png" alt="Featured image of post ES Introduction" /&gt;&lt;h2 id="利用倒排索引加速查询符合条件的文本"&gt;利用倒排索引加速查询符合条件的文本
&lt;/h2&gt;&lt;h3 id="利用倒排索引加速查询"&gt;利用倒排索引加速查询
&lt;/h3&gt;&lt;p&gt;对于若干段文本，例如：1: &amp;ldquo;I hava an orange&amp;rdquo;，2: &amp;ldquo;I hava a banana&amp;rdquo;，3: &amp;ldquo;I hava an apple&amp;rdquo;，想要查询&amp;quot;apple&amp;quot;在哪条记录里需要遍历所有文体，时间复杂度为O(n)。将文本进行切分，以切分后的文本作为键，文本ID作为值构成一个二维表格，这样可以大大降低查询时间。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;term&lt;/th&gt;
&lt;th&gt;文本id&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;I&lt;/td&gt;
&lt;td&gt;1、2、3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;have&lt;/td&gt;
&lt;td&gt;1、2、3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;an&lt;/td&gt;
&lt;td&gt;1、3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;orange&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;banana&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;apple&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;但当词项增多，遍历这些词项仍需花费大量时间，对词项进行倒排并进行二分查找可将时间复杂度降低到O(logN)。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Term dictionary&lt;/th&gt;
&lt;th&gt;Posting list&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;an&lt;/td&gt;
&lt;td&gt;1、3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;apple&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;banana&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;have&lt;/td&gt;
&lt;td&gt;1、2、3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;I&lt;/td&gt;
&lt;td&gt;1、2、3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;orange&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;将排好的词项称为Term dictionary，文档ID称为Posting list，构成的搜索结构称为inverted index（倒排索引）。&lt;/p&gt;
&lt;h3 id="利用term-index进一步加速查询"&gt;利用Term index进一步加速查询
&lt;/h3&gt;&lt;p&gt;将文本进行分词后得到的Term dictionary数据量巨大，只能通过磁盘检索。检索磁盘耗时较长，基于Term dictionary构建一颗字典树（Term index）并将字段树放入内存将极大加速索引效率。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/term_index.png"
width="431"
height="221"
srcset="https://zhaoyifengf.github.io/p/es-introduction/term_index_hu_cea63327e0a397ff.png 480w, https://zhaoyifengf.github.io/p/es-introduction/term_index_hu_2ee0346ee6cc0466.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="195"
data-flex-basis="468px"
&gt;&lt;/p&gt;
&lt;h3 id="利用store-fileds存储文档"&gt;利用Store Fileds存储文档
&lt;/h3&gt;&lt;p&gt;ES采用行式存储数据，对应存储结构被称为Store Fileds。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/store_fileds.png"
width="221"
height="171"
srcset="https://zhaoyifengf.github.io/p/es-introduction/store_fileds_hu_c1e7696731cd019d.png 480w, https://zhaoyifengf.github.io/p/es-introduction/store_fileds_hu_b999fa13a904b486.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="129"
data-flex-basis="310px"
&gt;&lt;/p&gt;
&lt;h3 id="利用doc-values实现快速聚合操作排序脚本计算"&gt;利用Doc Values实现快速聚合操作、排序、脚本计算
&lt;/h3&gt;&lt;p&gt;行式存储数据在进行大规模数据的聚合、排序以及脚本计算操作时效率低下，因此ES提供了列式存储结构Doc Values，针对单个字段进行集中存储，每行记录了字段值及其所在文档的文档ID。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/doc_values.png"
width="421"
height="121"
srcset="https://zhaoyifengf.github.io/p/es-introduction/doc_values_hu_c43deeacae58f1f7.png 480w, https://zhaoyifengf.github.io/p/es-introduction/doc_values_hu_8669eb0233fd1bd7.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="347"
data-flex-basis="835px"
&gt;&lt;/p&gt;
&lt;h3 id="segment"&gt;segment
&lt;/h3&gt;&lt;p&gt;segment是一个具备搜索功能的最小单元，包含了Inverted Index，Term Index，Stored Fileds，Doc Values四个模块。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/segment.png"
width="161"
height="251"
srcset="https://zhaoyifengf.github.io/p/es-introduction/segment_hu_bb81839976b255e6.png 480w, https://zhaoyifengf.github.io/p/es-introduction/segment_hu_166c6036305dda2.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="64"
data-flex-basis="153px"
&gt;&lt;/p&gt;
&lt;h3 id="lucene"&gt;Lucene
&lt;/h3&gt;&lt;p&gt;新增数据时不会立刻写入segment而是先写入内存缓冲区，等到执行refresh动作时将数据写入新的segment，在segment激活后才能参与搜索，已经写入的segment不可再进行写入。频繁的生成新的segment会导致数量过多，通过不定期将多个小segment合并为一个大segment可以减小segment数量。上面提到的就是大名鼎鼎的搜索引擎lucene的工作过程。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/lucene.png"
width="131"
height="161"
srcset="https://zhaoyifengf.github.io/p/es-introduction/lucene_hu_f426cccd309b8875.png 480w, https://zhaoyifengf.github.io/p/es-introduction/lucene_hu_35e8229c42c504ea.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="81"
data-flex-basis="195px"
&gt;&lt;/p&gt;
&lt;h2 id="es实现高性能高并发高扩展性"&gt;ES实现高性能、高并发、高扩展性
&lt;/h2&gt;&lt;h3 id="高性能"&gt;高性能
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;单个lucene读写性能过低，将数据按照业务划分，不同的数据写入不同的lucene可以提到读写并发度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;单个index name的数量扔热可能过多，对单个index name的数据进行分片，每个分片对应着一个lucene库，可进一步提高并发度。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="高扩展性"&gt;高扩展性
&lt;/h3&gt;&lt;p&gt;申请多个node，将不同的分片部署到不同的node上&lt;/p&gt;
&lt;h3 id="高可用"&gt;高可用
&lt;/h3&gt;&lt;p&gt;对每个分片部署多个副本，不同的副本部署到不同的节点上。&lt;/p&gt;
&lt;h3 id="node请求分化"&gt;node请求分化
&lt;/h3&gt;&lt;p&gt;若同一个node同时负责集群管理、存储数据、处理请求，在进行扩展时将同时扩展这几个能力，在实际使用时可能只需要扩展其中一两个能力，通过将功能进行分化，不同的node部署不同的功能，可实现能力的按需扩展。&lt;/p&gt;
&lt;h3 id="去中心化"&gt;去中心化
&lt;/h3&gt;&lt;p&gt;由于同时保护了多个node，需要对多个node进行管理选取其中主节点，使用zookeeper会导致系统过重，使用raft可实现去中心化选主。&lt;/p&gt;
&lt;h3 id="es-整体架构"&gt;ES 整体架构
&lt;/h3&gt;&lt;p&gt;&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/es.png"
width="608"
height="251"
srcset="https://zhaoyifengf.github.io/p/es-introduction/es_hu_e33e72a24d06855.png 480w, https://zhaoyifengf.github.io/p/es-introduction/es_hu_d0b00cf565125ed2.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="242"
data-flex-basis="581px"
&gt;&lt;/p&gt;</description></item></channel></rss>