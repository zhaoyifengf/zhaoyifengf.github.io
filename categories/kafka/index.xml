<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kafka on 峰峰的博客</title><link>https://zhaoyifengf.github.io/categories/kafka/</link><description>Recent content in Kafka on 峰峰的博客</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>峰峰</copyright><lastBuildDate>Mon, 10 Feb 2025 22:34:00 +0800</lastBuildDate><atom:link href="https://zhaoyifengf.github.io/categories/kafka/index.xml" rel="self" type="application/rss+xml"/><item><title>ES Introduction</title><link>https://zhaoyifengf.github.io/p/es-introduction/</link><pubDate>Mon, 10 Feb 2025 22:34:00 +0800</pubDate><guid>https://zhaoyifengf.github.io/p/es-introduction/</guid><description>&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/cover.png" alt="Featured image of post ES Introduction" />&lt;h2 id="利用倒排索引加速查询符合条件的文本">利用倒排索引加速查询符合条件的文本
&lt;/h2>&lt;h3 id="利用倒排索引加速查询">利用倒排索引加速查询
&lt;/h3>&lt;p>对于若干段文本，例如：1: &amp;ldquo;I hava an orange&amp;rdquo;，2: &amp;ldquo;I hava a banana&amp;rdquo;，3: &amp;ldquo;I hava an apple&amp;rdquo;，想要查询&amp;quot;apple&amp;quot;在哪条记录里需要遍历所有文体，时间复杂度为O(n)。将文本进行切分，以切分后的文本作为键，文本ID作为值构成一个二维表格，这样可以大大降低查询时间。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>term&lt;/th>
&lt;th>文本id&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>I&lt;/td>
&lt;td>1、2、3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>have&lt;/td>
&lt;td>1、2、3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>an&lt;/td>
&lt;td>1、3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>a&lt;/td>
&lt;td>2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>orange&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>banana&lt;/td>
&lt;td>2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apple&lt;/td>
&lt;td>3&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>但当词项增多，遍历这些词项仍需花费大量时间，对词项进行倒排并进行二分查找可将时间复杂度降低到O(logN)。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Term dictionary&lt;/th>
&lt;th>Posting list&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>a&lt;/td>
&lt;td>2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>an&lt;/td>
&lt;td>1、3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apple&lt;/td>
&lt;td>3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>banana&lt;/td>
&lt;td>2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>have&lt;/td>
&lt;td>1、2、3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>I&lt;/td>
&lt;td>1、2、3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>orange&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>将排好的词项称为Term dictionary，文档ID称为Posting list，构成的搜索结构称为inverted index（倒排索引）。&lt;/p>
&lt;h3 id="利用term-index进一步加速查询">利用Term index进一步加速查询
&lt;/h3>&lt;p>将文本进行分词后得到的Term dictionary数据量巨大，只能通过磁盘检索。检索磁盘耗时较长，基于Term dictionary构建一颗字典树（Term index）并将字段树放入内存将极大加速索引效率。&lt;/p>
&lt;p>&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/term_index.png"
width="431"
height="221"
srcset="https://zhaoyifengf.github.io/p/es-introduction/term_index_hu_cea63327e0a397ff.png 480w, https://zhaoyifengf.github.io/p/es-introduction/term_index_hu_2ee0346ee6cc0466.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="195"
data-flex-basis="468px"
>&lt;/p>
&lt;h3 id="利用store-fileds存储文档">利用Store Fileds存储文档
&lt;/h3>&lt;p>ES采用行式存储数据，对应存储结构被称为Store Fileds。&lt;/p>
&lt;p>&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/store_fileds.png"
width="221"
height="171"
srcset="https://zhaoyifengf.github.io/p/es-introduction/store_fileds_hu_c1e7696731cd019d.png 480w, https://zhaoyifengf.github.io/p/es-introduction/store_fileds_hu_b999fa13a904b486.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="129"
data-flex-basis="310px"
>&lt;/p>
&lt;h3 id="利用doc-values实现快速聚合操作排序脚本计算">利用Doc Values实现快速聚合操作、排序、脚本计算
&lt;/h3>&lt;p>行式存储数据在进行大规模数据的聚合、排序以及脚本计算操作时效率低下，因此ES提供了列式存储结构Doc Values，针对单个字段进行集中存储，每行记录了字段值及其所在文档的文档ID。&lt;/p>
&lt;p>&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/doc_values.png"
width="421"
height="121"
srcset="https://zhaoyifengf.github.io/p/es-introduction/doc_values_hu_c43deeacae58f1f7.png 480w, https://zhaoyifengf.github.io/p/es-introduction/doc_values_hu_8669eb0233fd1bd7.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="347"
data-flex-basis="835px"
>&lt;/p>
&lt;h3 id="segment">segment
&lt;/h3>&lt;p>segment是一个具备搜索功能的最小单元，包含了Inverted Index，Term Index，Stored Fileds，Doc Values四个模块。&lt;/p>
&lt;p>&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/segment.png"
width="161"
height="251"
srcset="https://zhaoyifengf.github.io/p/es-introduction/segment_hu_bb81839976b255e6.png 480w, https://zhaoyifengf.github.io/p/es-introduction/segment_hu_166c6036305dda2.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="64"
data-flex-basis="153px"
>&lt;/p>
&lt;h3 id="lucene">Lucene
&lt;/h3>&lt;p>新增数据时不会立刻写入segment而是先写入内存缓冲区，等到执行refresh动作时将数据写入新的segment，在segment激活后才能参与搜索，已经写入的segment不可再进行写入。频繁的生成新的segment会导致数量过多，通过不定期将多个小segment合并为一个大segment可以减小segment数量。上面提到的就是大名鼎鼎的搜索引擎lucene的工作过程。&lt;/p>
&lt;p>&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/lucene.png"
width="131"
height="161"
srcset="https://zhaoyifengf.github.io/p/es-introduction/lucene_hu_f426cccd309b8875.png 480w, https://zhaoyifengf.github.io/p/es-introduction/lucene_hu_35e8229c42c504ea.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="81"
data-flex-basis="195px"
>&lt;/p>
&lt;h2 id="es实现高性能高并发高扩展性">ES实现高性能、高并发、高扩展性
&lt;/h2>&lt;h3 id="高性能">高性能
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>单个lucene读写性能过低，将数据按照业务划分，不同的数据写入不同的lucene可以提到读写并发度&lt;/p>
&lt;/li>
&lt;li>
&lt;p>单个index name的数量扔热可能过多，对单个index name的数据进行分片，每个分片对应着一个lucene库，可进一步提高并发度。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="高扩展性">高扩展性
&lt;/h3>&lt;p>申请多个node，将不同的分片部署到不同的node上&lt;/p>
&lt;h3 id="高可用">高可用
&lt;/h3>&lt;p>对每个分片部署多个副本，不同的副本部署到不同的节点上。&lt;/p>
&lt;h3 id="node请求分化">node请求分化
&lt;/h3>&lt;p>若同一个node同时负责集群管理、存储数据、处理请求，在进行扩展时将同时扩展这几个能力，在实际使用时可能只需要扩展其中一两个能力，通过将功能进行分化，不同的node部署不同的功能，可实现能力的按需扩展。&lt;/p>
&lt;h3 id="去中心化">去中心化
&lt;/h3>&lt;p>由于同时保护了多个node，需要对多个node进行管理选取其中主节点，使用zookeeper会导致系统过重，使用raft可实现去中心化选主。&lt;/p>
&lt;h3 id="es-整体架构">ES 整体架构
&lt;/h3>&lt;p>&lt;img src="https://zhaoyifengf.github.io/p/es-introduction/es.png"
width="608"
height="251"
srcset="https://zhaoyifengf.github.io/p/es-introduction/es_hu_e33e72a24d06855.png 480w, https://zhaoyifengf.github.io/p/es-introduction/es_hu_d0b00cf565125ed2.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="242"
data-flex-basis="581px"
>&lt;/p></description></item><item><title>Kafka Introduction</title><link>https://zhaoyifengf.github.io/p/kafka-introduction/</link><pubDate>Mon, 27 Jan 2025 00:28:09 +0800</pubDate><guid>https://zhaoyifengf.github.io/p/kafka-introduction/</guid><description>&lt;img src="https://zhaoyifengf.github.io/p/kafka-introduction/cover.png" alt="Featured image of post Kafka Introduction" />&lt;h2 id="一步步看kfka">一步步看Kfka
&lt;/h2>&lt;h3 id="直接调用接口的弊端">直接调用接口的弊端
&lt;/h3>&lt;p>&lt;img src="https://zhaoyifengf.github.io/p/kafka-introduction/direct-send-msg.svg"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>系统耦合度提升&lt;/li>
&lt;li>当生产者的生产速度大于消费者的消费速度时会导致消费者来不及处理导致消息丢失&lt;/li>
&lt;/ul>
&lt;h3 id="消费者添加消息队列实现消息缓冲">消费者添加消息队列实现消息缓冲
&lt;/h3> &lt;img src="add-queue-to-consumer.svg" width="60%" height="60%">
&lt;p>很容想到在消费者中提供一个消息队列缓冲没有能够及时处理的消息，通过offset记录已经处理的消息。但这样做仍然会存在以下问题：&lt;/p>
&lt;ul>
&lt;li>在消费者重启后消息会丢失&lt;/li>
&lt;li>每个消费者都维护一个消息队列存在着重复造轮子的问题&lt;/li>
&lt;li>生产者和消费者耦合的问题并没有解决&lt;/li>
&lt;/ul>
&lt;h3 id="将消息队列独立成一个服务">将消息队列独立成一个服务
&lt;/h3> &lt;img src="simple-msg-queue.svg" width="60%" height="60%">
&lt;p>将消息队列抽成一个单独的服务使其可以服务于各个业务避免了重复造轮子的问题，实现了生产者和消费者之间的解耦，并且消息持久化、防止消息丢失的逻辑都可在一个服务中实现，独立于业务逻辑。在消息队列服务中我们需要实现高性能、高扩展。&lt;/p>
&lt;h3 id="实现消息队列的高性能展性">实现消息队列的高性能展性
&lt;/h3>&lt;h4 id="根据topic定义多消息队列">根据topic定义多消息队列
&lt;/h4> &lt;img src="multi-producer-consumer.svg" width="60%" heigh="60%">
&lt;p>通过增加生产者和消费者可以增加生产消息和消费消息的速度。单个消息队列将导致生产者和消费者竞争同一个队列，消息队列将成功性能的瓶颈。但不同业务下的消息并没有关联，也自然没有必要将所有的消息都通过一个消息队列处理。将同一个业务定义下的消息归纳到一个消息队列下（topic队列），这样就将消息队列中的一个消息队列拆分为多个topic队列，大大提升了消息的处理速度。&lt;/p>
&lt;img src="topic-queue.svg" width="60%" height="60%">
&lt;p>当一个topic消息量大时，当前的设计仍然无法满足高性能需求。&lt;/p>
&lt;h4 id="使用partition进一步提高并发度">使用partition进一步提高并发度
&lt;/h4> &lt;img src="simple-partition.svg" width="60%" height="60%">
&lt;p>对同一个topic再进行切分，每个partition对应着一个队列，不同消费者处理不同的消息队列。&lt;/p>
&lt;h4 id="consumer-group-实现多消费者的业务隔离">consumer-group: 实现多消费者的业务隔离
&lt;/h4> &lt;img src="consumer-group.svg" width="60%" height="60%">
&lt;p>在上面提到的优化策略中，多个消费者协作处理一个topic，也就是一个消息只能被一个消费者消费。在实际业务需求中，同一个消息需要被多个业务线处理，这样就引入了消费者组的概念，同一个消费者组中的消费者协作处理同一个消息（一个消息只能被消费者组中的一个消费者处理），不同消费者组互不影响。&lt;/p>
&lt;h3 id="实现消息队列的高扩展性">实现消息队列的高扩展性
&lt;/h3>&lt;p>在上面的步骤中，通过对消息队列切分再切分已经大大提高了消息队列的性能，但整个消息队列的性能仍受机器的限制，需要通过扩展机器提高整个消费队列服务的性能。&lt;/p>
&lt;img src="simple-broker.svg" width="60%" height="60%">
&lt;p>通过将同一个topic中的不同partition分布在不同的broker上，再将多个broker构成一个kafka集群，实现硬件能力的扩展，提高kafka的处理速度。&lt;/p>
&lt;h3 id="实现消息队列的高可用">实现消息队列的高可用
&lt;/h3>&lt;h4 id="解决单个broker宕机一主多从">解决单个broker宕机：一主多从
&lt;/h4> &lt;img src="one-leader-multi-follower.svg" width="60%" height="60%">
&lt;p>对每个partition，创建一个主节点，多个从节点，主节点负责读写，从节点只负责从主节点拉取数据、作数据备份。当某个broker宕机后，重新选取partition作为主节点。&lt;/p>
&lt;h4 id="解决所有broker宕机数据持久化与过期策略">解决所有broker宕机：数据持久化与过期策略
&lt;/h4> &lt;img src="persistence.svg" width="60%" height="60%">
&lt;p>如果数据都存储在内存中，当所有broker都宕机后未消费的消息将丢失，通过持久化并重启服务可实现服务宕机后的数据恢复。数据不断写入磁盘将会导致磁盘空间占满，需要一种过期策略剔除过期数据。&lt;/p>
&lt;h2 id="kafka基本操作">Kafka基本操作
&lt;/h2></description></item></channel></rss>