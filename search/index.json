[{"content":"分布式事务基本概念 分布式系统架构演进 单体应用架构 在单体应用架构下所有功能都被打包成一个服务并部署，这种架构具有如下优点：\n架构简单、项目开发和维护成本低 所有项目部署在一起，方便维护。 但单体应用架构也存在诸多缺陷：\n所有模块耦合在一起，不容易开发和维护（合并分支需要解决冲突，大项目启动事件长） 项目模块过于耦合，一个模块出问题可能导致整个项目不可用 无法针对某个具体模块提升性能（所有的模块都部署在一起，无法针对单个模块进行水平扩展） 无法对项目进行水平扩展（项目大启动时间长，项目部署低效） 垂直应用架构 垂直应用架构将系统按照业务领域进行拆分，当有业务领域流量增大只需要针对单个业务领域增加节点，无需对整个项目增加服务器节点。该架构具有如下优点：\n可以针对不同系统进行优化 能够实现水平扩展 各系统能够分担流量，减小并发度 系统与系统隔离，单系统出现故障不影响其他系统运行 垂直应用架构仍然存在如下缺点：\n拆分后的系统之间相互独立，无法进行相互调用 拆分粒度大，重复代码片段多，会出现重复开发与难以维护的问题 分布式架构 分布式架构在垂直架构的基础上，将重复的代码抽出来独立未单独的服务。整个系统被拆分为服务层和表现层，表现层负责处理与页面的交互，服务层则封装了具体的业务逻辑供表现层调用。这种架构具有如下优点：\n提高了代码的服用程度，降低了维护成本。 可以针对服务进行性能优化。 但该架构具有如下缺点：\n系统之间的调用关系变得复杂 系统之间的依赖关系变得复杂 系统维护成本变高 SOA架构 SOA架构引入了注册中心解决了服务依赖与调用关系的自动注册与发现。但这种架构有如下缺点：\n各服务间存在依赖关系，如果某个服务出现故障可能会造成服务器崩溃。 服务间的依赖与调用关系复杂增加了测试和运维成本。 微服务架构 微服务架构与SOA架构相比有如下差异：\n服务大小：在SOA架构中，服务通常是大型的负责多个业务功能；微服务架构中服务负责的功能更具体，通常是某个业务的具体功能。 数据存储：在SOA架构个中服务共用同一个数据库；微服务每个服务通常拥有自己的数据库。 通信协议：SOA通常采用SOAP等复杂的通信协议；微服务通常采用REST或gRPC。 服务协调：SOA通常采用中心话的协调方式如ES；微服务通常采用去中心化的服务方式，如API网关。 部署方式：SOA通常集中部署；微服务一般进行单独部署。 在SOA架构中，服务通常是大型的负责多个业务功能，不同服务共用一个数据库，\n分布式事务场景 一个事务需要多个服务远程协作完成就会产生分布式事务问题，分布式事务会在三种场景下产生，分别是跨JVM进程、跨数据库实例、和多服务访问单数据库。\n跨JVM进程（多服务、多数据库） 跨数据库实例（单服务、多数据库） 和多服务访问单数据库（多服务、单数据库） 数据一致性 数据一致性问题包含多副本、调用超时、缓存与数据库不一致、多个缓存节点数据不一致等场景。\n调用超时场景 调用超时指的是A服务同步或者异步调用B服务超时，导致A服务与B服务数据不一致。\n缓存与数据库不一致 在高并发场景下，一些热点数据会缓存到Redis等组件中，此时如果对数据库中的数据进行写操作将会导致缓存中的数据与数据库中的数据不一致。\n多缓存节点数据不一致 缓存内部各节点数据不一致，如在Redis集群中，由于网络问题导致多个缓存节点数据不一致。\n分布式事务理论知识 CAP（Consistency、Availability、Partition Tolerance）理论 CAP理论：在分布式系统，不会同时具备CAP三个特性，只能同时具备其中两个。\n一致性\n用户对数据的写操作在所有数据副本要么都成功、要么都失败。\n可用性\n客户端访问数据时能够快速得到响应。\n分区容忍性\n分区：分布式系统中不同节点间通信出现了问题。分区容忍：在出现分区时系统仍然能对外提供服务。\n为什么CAP只能满足其中两个 首先需要明确的是一个分布式系统必需要满足分区容错，也就是CAP中的P。在分布式系统中分区是一定会出现的，没有人能够保证节点与节点之间的网络总是不出问题，也没有人能够保证单个节点始终运行正常。如果一个分布式系统出现分区整个系统就停止服务，那其与单体服务并无区别（分布式系统的初衷就是通过多节点部署来提高系统的可用性）。\n在出现分区的情况下，一致性与可用性只能满足其一：\n若要满足一致性，在对数据的多副本进行写入时需要锁定资源，而出现分区导致无法确认所有副本都写入成功，客户端的访问也无法在有效时间内得到响应。\n若要满足可可用性，对任意节点的访问都需要在指定时间得到响应，当被访问节点数据写入成功而存在节点数据未写入成功或者被访问节点数据未写入成功而其余节点数据写入成功则可用性也无法得到满足。\nBASE（Basically Available, Soft State， Eventually Consistent）理论 当出现分区时，BASE理论允许部分数据不可用，但会保证核心功能可用；允许数据在一定时间内不一致，但经过一段时间数据最终是一致的。\n基本可用\n基本可用指的是分布式系统出现故障时，允许损失部分可用性（比如响应时间或部分功能）\n软状态\n软状态指的是允许系统出现中间状态，但中中间状态不会影响系统的整体可用性。\n最终一致性\n最终一致性指的是允许允许数据在各个节点存在不一致，只需要数据最终一致。\n分布式事务解决方案 强一致性分布式事务解决方案 强一致性事务要求任意时刻参与全局事务的各个节点的数据都一致。\n强一致性事务的三种方案 全局事务模型（DTP） 基本概念\n事务：一个完整的工作单元，具备ACID特性 全局事务：事务管理器管理的全局事务，能一次操作多个资源管理器 分支事务：全局事务中的每个资源管理器中独立执行的事务 控制线程：执行全局事务的线程 执行流程 DTP模型中的三个核心组件：\nAP（应用程序、Application Program）：参与DTP分布式事务模型的应用程序。 RM（资源管理器、Resource Manager）：数据库管理系统或者消息服务管理器，用来对响应的资源进行有效的控制，相应的资源需要实现XA定义的接口。 TM（事务管理器、Transaction Manager）：负责协调和管理DTP模型中的事务，为应用程序提供编程接口，同时管理资源管理器。 二阶段提交模型（2PC） 2PC模型即两阶段提交协议模型，该模型将事务流程分为Prepare阶段和Commit阶段。\nPrepare阶段\n在Prepare阶段，事务管理器给每个参与全局事务的资源管理器发送Prepare消息，资源管理器要么返回失败，要么在本地执行相应的事务，将事务写入本地的Redo Log文件和Undo Log文件，但此时事务并未提交。\n如果在Prepare阶段有资源管理器返回了失败消息则在Commit阶段事务管理器会向其他响应正常消息发送回滚消息。\nCommit阶段\n在2PC的commit阶段，事务管理器向参与全局事务的资源管理器发送commit消息，资源管理器收到消息后提交本地事务并将提交成功的消息返回给事务管理器。\n三阶段提交模型（3PC） 相比与2PC模型，3PC模型将prepare阶段分成了CanCommit阶段与PreCommit阶段。\nCanCommit阶段 在CanCommit阶段，事务管理器会向资源管理器发送CanCommit消息，资源管理器如果认为可以执行任务则发送确认消息并进入预备状态。\nPreCommit阶段 在PreCommit阶段，资源管理器接受到消息并写入undo log与redo log。\nDoCommit阶段 在DoCommit阶段，资源管理器收到消息并提交事务。如果超过一定时间资源管理器没有收到事务管理器发送的事务回滚消息则会直接提交事务，如果其资源管理器收到了回滚消息则会导致数据不一致。\n最终一致性的三种解决方案 强一致性方案要求参与事务的各个节点的数据时刻保持一致，在高并发场景下会影响性能。最新一致性方案不要求各个节点的数据始终保持一致，只要数据最终一致即可。\n服务模式 可查询操作 可查询操作服务模型要求操作具有唯一标识（唯一业务标识及操作时间）并且要求其他服务在提供操作接口的情况下提供查询接口及批量查询接口，在分布式环境下可以通过查询接口确认操作是否我那次。\n幂等操作 幂等操作要求对于同一个方法相同的参数，操作一次和操作多次的结果相同。在分布式环境下，常常需要重试，而幂等可保证重试对最终结果没有影响。\nTCC操作 TCC模式包含Try，Commit，Cancel三个阶段。在try阶段完成所有业务的一致性检查、预留必要的业务资源，并需要与其他操作隔离。在Commit执行真正的业务操作。在Cancel释放预留的资源。\n可补偿操作 在分布式环境下数据可能出现不一致，这时需要通过补偿接口进行补偿。 在分布式环境下数据可能出现不一致，这时需要通过补偿接口进行补偿。\nTCC 方案 Try阶段 在 Try 阶段在具体的业务数据进行修改操作并标记状态为待提交，并记录此阶段的反向操作（如增加多少库存）\nConfirm阶段 如果 Try 阶段执行全部成功，则将待提交状态标记为提交状态并取消反向操作。\nCancel阶段 标记操作的具体业务数据状态为取消，并对业务数据进行反向操作，清除具体的反向操作。\n可靠消息最终一致性解决方案 事务发起方发送可靠消息，事务参与方从可靠消息服务接收消息。由于事务发起方和可靠消息服务、可靠消息服务和事务参与方之间都是通过网络进行通信的，所以需要引入消息确认服务和消息回复服务。\n消息确认服务会定期检测事务发起方业务的执行状态和消息库中的数据，如果发现事务发起方业务的执行状态与消息库中的数据不一致，消息确认服务就会同步事务发起方的业务数据和消息库中的数据，保证数据一致性。\n消息恢复服务会定期检测事务参与方业务执行状态与消息库中数据是否一致，如果发现不一致则回滚消息状态为事务发起方发送消息但未被事务参与方消费的状态。\n最大努力通知型解决方案 业务方在完成业务处理后，会向业务参与方发送消息，发送消息时通知时运行消息丢失。业务方需要体统查询接口供业务接收方按需查询，用于恢复丢失的消息。\n分布式事务原理 可靠消息分布式事务 可靠消息的三个角色 三个角色与对应职责：\n事务参与方：执行事务并发送消息（在诸如RocketMQ等独立消息服务不需要事务参与方保证消息投递与事务提交满足原子性） 独立消息服务：在出现分区的情况下保证 1. 若事务发起方事务执行状态与可靠消息中间事务消息提交状态一致 2. 独立消息服务消息消费状态与消费者消费状态一致 消息消费者：事务执行失败能正确通知事务参与方回滚事务 两条链路：\n事务提交链路：事务发起方 -\u0026gt; 独立消息服务 -\u0026gt; 事务参与方 事务回滚链路：事务参与方 -\u0026gt; 独立消息服务 -\u0026gt; 事务发起方 在诸如RocketMQ等独立消息服务中只保证事务发起方事务执行与事务参与方消息消费一致但并保证事务参与方事务执行结果与事务参与方消息消费结果一致，即其只提供了事务提交链路的一致，事务回滚链路的一致需要手动保证。\n各个角色实现任务的难点 事务参与方如何保证事务提交与消息投递是原子操作\n先发消息\n执行事务前发消息：消息发送成功但事务执行失败，只回滚了事务并没有实现消息发送和写库都执行失败或者都执行成功。如果消息接收方通过接口回调来确认消息状态，在读已提交和可重复读的隔离级别下设置回调时间过短可能导致没有正确获取到事务的执行状态。 执行事务时发送消息：在写库完成前发送消息可能会出现消息发送成功，但写库失败的场景。在网络波动是，发送消息等待响应时间长，会阻塞事务执行，影响系统安全。 先写库\n执行事务后发送消息：在提交事务后设置回调发送消息，单事务已提交，消息可能发送失败。 事务执行时发送消息：在写库完成后发送消息，发送消息失败则回滚。在网络波动时，发送消息等待响应时间长，会阻塞事务执行，影响系统安全。 上面的两种方式还可按照 在事务内发消息还是在事务外发消息划分，二者各有如下缺点\n在事务内发消息\n在事务内发消息，在网络超时，生产者重试，可能阻塞事务导致死锁等问题。\n在事务外发消息\n难以保证事务执行成功消息提交成功是原子操作。\n独立消息服务平台如何保 消息状态正确\n如何保证事务发起方事务执行状态与消息状态一致 在网络超时时，事务发起方认为消息发送失败，但消息可能投递成功，导致事务参与方与事务发起方状态不一致。 如何事务参与方消息消费状态与消息状态一致 在网络波动时，消费者没有在指定时间返回消息处理状态，独立消息服务错误地将消息消费状态标记为失败。 在事务内发送消息会影响数据安全是必须要避免的，现在需要解决的问题是如何在事务外发送消息的情况下保证： 发送消息成功、提交事务、投递消息成功、消费消息成功要么全做要么全不做。\n本地消息表 工作过程\n事务发起方提交事务\n事务发起方在写业务数据时向本地消息表也写一份数据用于记录需要发送的消息，并且将两个写操作放在一个事务中保证业务数据写操作与本地消息表的记录要么全做要么全不做。\n事务发起方发送消息\n使用定时任务不断扫描本地消息表，发送消息至消息中间件，如果消息没有发送成功则会不断重试，在重试一定次数仍然失败之后则会把消息放入实信对列，之后进行人工干预。\n事务参与方接收消息并消费\n各角设如何保证完成自己的任务\n事务发起方如何保证提交事务和发送消息是一个原子操作\n本地消息表将写业务数据与写本地消息表放在一个事务里，保证这两个操作能同时执行，此外通过不断重试消息并引入人工处理来保证消息一定能够发送并被消费者消费。\n消息中间件如何保证成功返回消息消费状态\n事务参与方提交事务失败时发送一个消息给事务发起方通知其回滚消息。\n优点\n本地消息表是业界内比较成熟的方案，可靠性高。 本地消息表实现了数据的最终一致性。 缺点\n可靠消息保证与业务代码耦合，需要额外开发定时任务等逻辑。 可靠消息保证的相关逻辑无法复用，需要重复开发。 注意点\n事务提交后需要保证消息一定投递成功，可能会频繁重试，事务参与方需要保证消息的幂等。 事务参与方通过消息投递通知事务发起方回滚，事务参与方也需要保证消息可靠投递。 独立消息服务 独立消息服务的三个角色：\n可靠消息服务：负责消息状态维护、消息接收与投递 消息确认服务：负责保障消息投递方与可靠消息服务中的消息状态一致 消息恢复服务：用于宕机时的消息恢复 独立消息服务将本地消息表中可靠消息保证的逻辑抽离成独立服务并进行了增强，其工作步骤如下：\n事务发起方发送Half消息至可靠消息服务，发送成功后执行本地事务。 可靠消息服务接收到消息后存储到消息库中并将消息状态标记为“待发送”但不会立即发送消息至消息中间件。 事务执行成功或失败后事务发起方向可靠消息服务发送确认消息。 可靠消息服务接收到事务发起方投递消息，若收到确认消息则将消息发送至中间件并将消息状态标记为已发送；若收到取消消息则将消息库中保存的消息标记为已删除。 消息中间件投递消息至事务参与方，事务参与方接收消息并将处理结果返回给消息中间件。 消息中间件将消费结果投递至可靠消息服务，可靠消息服务接收到确认消息将消息状态标记为已完成。 各个角色如何保证完成自己的任务\n事务发起方如何保证提交事务和发送消息是一个原子操作\n执行事务前发送消息失败：发送消息失败事务发起方不会提交事务，如果因网络超时事务发起方发送事务成功但没有收到正确响应，可靠消息服务没有接收到确认消息也不会向事务产生方投递消息。 执行事务成功如何确保发送确认消息成功：执行事务成功，消息发送失败事务发起方与事务参与方状态不一致，消息确认服务会不断校对事务发起方和消息库中消息的状态，发现不一致时会进行校对。 独立消息服务如何确保证消息状态与事务发起方事务执行状态与事务消费方消费状态一致\n消息与事务发起方状态一致：消息确认服务会不断地对事务发起方事务的执行状态和消息库中消息的状态进行校准。 消息与事务参与方状态一致：可靠消息服务会重试消息投递，重试失败后会由消息恢复服务定时重试。 一点讨论\n独立消息服务一般只保证事务提交链路的一致性，因此可靠消息服务需要确保 若事务发起方提交事务则事务参与方一定能消费消息，可靠消息服务是通过一定次数的重试来实现的。 独立消息服务包含了一个假设：按照指定规则经过一定次数重试事务参与方一定能消费消息成功。这个假设一般都是成了的，网络波动或者消息者自身问题消费消息失败都是偶然的，通过一定规则重试是能保证消息消费成功的。 可靠消息能保证最终一致性：在事务参与方提交事务后即时独立消息服务或消息消费服务宕机，重启服务后独立消息服务通过消息确认服务与消息回复服务也能保证消息的最终一致性。 RocketMQ事务消息 RocketMQ工提供了事务消息，工作过程与独立消息服务基本一致，下面我们通过代码来学习RocketMQ事务消息。\n假设我们有一个商场业务下单扣减库存的场景，订单微服务和库存微服务分别部署，订单微服务在生成订单后需要通知库存微服务扣减库存。\n总共涉及到三张表，order表用来存储订单数据，stock表用来存储库存数据，tx_log表用来记录事务。 工作过程如下\n订单服务需要在执行事务前发送Half消息至RocketMQ并在RocketMQ成功接收到消息后提交事务并发送确认消息到RocketMQ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Service public class OrderService { @Autowired private OrderMapper orderMapper; @Autowired RocketMQTemplate rocketMQTemplate; @Override @Transactional(rollbackFor = Exception.class) public void submitOrderAndSaveTxNo(TxMessage txMessage) { Integer existsTx = orderMapper.isExistsTx(txMessage.getTxNo()); if(existsTx != null){ log.info(\u0026#34;订单微服务已经执行过事务,商品id为:{}，事务编号为:{}\u0026#34;,txMessage.get ProductId(), txMessage.getTxNo()); return; } //生成订单 Order order = new Order(); order.setId(System.currentTimeMillis()); order.setCreateTime(new Date()); order.setOrderNo(String.valueOf(System.currentTimeMillis())); order.setPayCount(txMessage.getPayCount()); order.setProductId(txMessage.getProductId()); orderMapper.saveOrder(order); //添加事务日志 orderMapper.saveTxLog(txMessage.getTxNo()); } @Override public void submitOrder(Long productId, Integer payCount) { //生成全局分布式序列号 String txNo = UUID.randomUUID().toString(); TxMessage txMessage = new TxMessage(productId, payCount, txNo); JSONObject jsonObject = new JSONObject(); jsonObject.put(\u0026#34;txMessage\u0026#34;, txMessage); Message\u0026lt;String\u0026gt; message = MessageBuilder.withPayload(jsonObject.to JSONString()).build(); //发送一条事务消息 rocketMQTemplate.sendMessageInTransaction(\u0026#34;tx_order_group\u0026#34;, \u0026#34;topic_txmsg\u0026#34;, message, null); } } RocketMQ在接收到订单服务的半消息后需要通知订单服务，此外在订单服务发送事务提交消息至RocketMQ失败后RocketMQ需要不断校验事务发起方状态. RocketMQ提供了RocketMQLocalTransactionListener类，executeLocalTransaction方法会在事务发送方法发送消息成功后被回调，在该方法内执行时服务发送方的提交事务逻辑并提交事务提交消息至RocketMQ。这里需要注意，事务提交的逻辑和发送事务提交消息的逻辑并不再一个方法里。\nROcketMQ还提供了checkLocalTransaction方法用于检查事务提交方的状态，避免事务消息发送失败导致的事务发起方和参与方状态不一致。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @Component @RocketMQTransactionListener(txProducerGroup = \u0026#34;tx_order_group\u0026#34;) public class OrderTxMessageListener implements RocketMQLocalTransactionListener { @Autowired private OrderService orderService; @Autowired private OrderMapper orderMapper; @Override @Transactional(rollbackFor = Exception.class) public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object obj) { try{ log.info（\u0026#34;订单微服务执行本地事务\u0026#34;）; TxMessage txMessage = this.getTxMessage(msg); //执行本地事务 orderService.submitOrderAndSaveTxNo(txMessage); //提交事务 log.info（\u0026#34;订单微服务提交事务\u0026#34;）; return RocketMQLocalTransactionState.COMMIT; }catch (Exception e){ e.printStackTrace(); //异常回滚事务 log.info（\u0026#34;订单微服务回滚事务\u0026#34;）; return RocketMQLocalTransactionState.ROLLBACK; } } @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) { log.info（\u0026#34;订单微服务查询本地事务\u0026#34;）; TxMessage txMessage = this.getTxMessage(msg); Integer exists = orderMapper.isExistsTx(txMessage.getTxNo()); if(exists != null){ return RocketMQLocalTransactionState.COMMIT; } return RocketMQLocalTransactionState.UNKNOWN; } private TxMessage getTxMessage(Message msg){ String messageString = new String((byte[]) msg.getPayload()); JSONObject jsonObject = JSONObject.parseObject(messageString); String txStr = jsonObject.getString(\u0026#34;txMessage\u0026#34;); return JSONObject.parseObject(txStr, TxMessage.class); } } 库存微服务逻辑相对简单，只需消息消息即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Component @RocketMQMessageListener(consumerGroup = \u0026#34;tx_stock_group\u0026#34;, topic = \u0026#34;topic_txmsg\u0026#34;) public class StockTxMessageConsumer implements RocketMQListener\u0026lt;String\u0026gt; { @Autowired private StockService stockService; @Override public void onMessage(String message) { log.info（\u0026#34;库存微服务开始消费事务消息:{}\u0026#34;, message）; TxMessage txMessage = this.getTxMessage(message); stockService.decreaseStock(txMessage); } private TxMessage getTxMessage(String msg){ JSONObject jsonObject = JSONObject.parseObject(msg); String txStr = jsonObject.getString(\u0026#34;txMessage\u0026#34;); return JSONObject.parseObject(txStr, TxMessage.class); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Service public class StockService { @Autowired private StockMapper stockMapper; @Override public void decreaseStock(TxMessage txMessage) { log.info(\u0026#34;库存微服务执行本地事务,商品id:{}, 购买数量:{}\u0026#34;, txMessage.getProductId(), txMessage.getPayCount()); //检查是否执行过事务 Integer exists = stockMapper.isExistsTx(txMessage.getTxNo()); if(exists != null){ log.info(\u0026#34;库存微服务已经执行过事务,事务编号为:{}\u0026#34;, txMessage.getTxNo()); } Stock stock = stockMapper.getStockByProductId(txMessage.getProductId()); if(stock.getTotalCount() \u0026lt; txMessage.getPayCount()){ throw new RuntimeException（\u0026#34;库存不足\u0026#34;）; } stockMapper.updateTotalCountById(txMessage.getPayCount(), stock.getId()); //记录事务日志 stockMapper.saveTxLog(txMessage.getTxNo()); } } 最大努力通知型分布式事务 适用场景 允许丢失消息 事务发起方需要提供接口让事务参与回查进行数据校准 事务参与方的结果不影响事务发起方的结果 对消息实时性要求不高 工作过程 事务参与方执行事务后发送消息 消息中间件接收消息后将消息标记为待发送 消息中间件向事务参与方投递消息 业务场景 业务场景 场景描述 特点与适用条件 示例说明 支付成功通知商户 用户支付成功后，支付平台需通知商户系统发货或履约 支付成功事件已在支付系统本地提交，通知为异步重试多次，允许因网络或系统原因有延迟，但要求最终送达或人工处理 微信支付/支付宝在支付回调失败时，会间隔多次重试通知商户接口 订单状态变更通知 电商平台订单状态变化（已发货/已收货）需要通知物流、会员积分等系统 状态变化事件已写入订单库，不阻塞交易主流程，通过消息或HTTP回调多次发送 物流同步接口失败会隔一段时间重试，多数场景允许几分钟内延迟同步 异步库存同步 核心交易系统与库存系统解耦，交易成功后通知库存系统扣减 交易已完成且不可逆，通知可延迟执行，通过补偿或定时任务保证一致性 生鲜电商交易完成后，库存系统可能因网络抖动导致同步延迟 用户行为上报 APP端关键行为（观看、点击、分享）发送到埋点分析系统 埋点数据允许丢失少量信息，但希望尽量多送达，提高数据准确度 行为日志先入本地队列，后台重试发送到数据平台 发票开具通知 用户付款后通知财税系统开具电子发票 可以异步通知，避免交易阻塞，财税接口短时不可用时可多次重试 第三方发票平台偶尔超时，异步通知能显著提升整体体验 ","date":"2025-02-10T22:34:00+08:00","image":"https://zhaoyifengf.github.io/p/distribution-transaction/cover_hu_9ba935a650dc6318.png","permalink":"https://zhaoyifengf.github.io/p/distribution-transaction/","title":"Distribution Transaction"},{"content":"利用倒排索引加速查询符合条件的文本 利用倒排索引加速查询 对于若干段文本，例如：1: \u0026ldquo;I hava an orange\u0026rdquo;，2: \u0026ldquo;I hava a banana\u0026rdquo;，3: \u0026ldquo;I hava an apple\u0026rdquo;，想要查询\u0026quot;apple\u0026quot;在哪条记录里需要遍历所有文体，时间复杂度为O(n)。将文本进行切分，以切分后的文本作为键，文本ID作为值构成一个二维表格，这样可以大大降低查询时间。\nterm 文本id I 1、2、3 have 1、2、3 an 1、3 a 2 orange 1 banana 2 apple 3 但当词项增多，遍历这些词项仍需花费大量时间，对词项进行倒排并进行二分查找可将时间复杂度降低到O(logN)。\nTerm dictionary Posting list a 2 an 1、3 apple 3 banana 2 have 1、2、3 I 1、2、3 orange 1 将排好的词项称为Term dictionary，文档ID称为Posting list，构成的搜索结构称为inverted index（倒排索引）。\n利用Term index进一步加速查询 将文本进行分词后得到的Term dictionary数据量巨大，只能通过磁盘检索。检索磁盘耗时较长，基于Term dictionary构建一颗字典树（Term index）并将字段树放入内存将极大加速索引效率。\n利用Store Fileds存储文档 ES采用行式存储数据，对应存储结构被称为Store Fileds。\n利用Doc Values实现快速聚合操作、排序、脚本计算 行式存储数据在进行大规模数据的聚合、排序以及脚本计算操作时效率低下，因此ES提供了列式存储结构Doc Values，针对单个字段进行集中存储，每行记录了字段值及其所在文档的文档ID。\nsegment segment是一个具备搜索功能的最小单元，包含了Inverted Index，Term Index，Stored Fileds，Doc Values四个模块。\nLucene 新增数据时不会立刻写入segment而是先写入内存缓冲区，等到执行refresh动作时将数据写入新的segment，在segment激活后才能参与搜索，已经写入的segment不可再进行写入。频繁的生成新的segment会导致数量过多，通过不定期将多个小segment合并为一个大segment可以减小segment数量。上面提到的就是大名鼎鼎的搜索引擎lucene的工作过程。\nES实现高性能、高并发、高扩展性 高性能 单个lucene读写性能过低，将数据按照业务划分，不同的数据写入不同的lucene可以提到读写并发度\n单个index name的数量扔热可能过多，对单个index name的数据进行分片，每个分片对应着一个lucene库，可进一步提高并发度。\n高扩展性 申请多个node，将不同的分片部署到不同的node上\n高可用 对每个分片部署多个副本，不同的副本部署到不同的节点上。\nnode请求分化 若同一个node同时负责集群管理、存储数据、处理请求，在进行扩展时将同时扩展这几个能力，在实际使用时可能只需要扩展其中一两个能力，通过将功能进行分化，不同的node部署不同的功能，可实现能力的按需扩展。\n去中心化 由于同时保护了多个node，需要对多个node进行管理选取其中主节点，使用zookeeper会导致系统过重，使用raft可实现去中心化选主。\nES 整体架构 ","date":"2025-02-10T22:34:00+08:00","image":"https://zhaoyifengf.github.io/p/es-introduction/cover_hu_a93c4dc710fcd99f.png","permalink":"https://zhaoyifengf.github.io/p/es-introduction/","title":"ES Introduction"},{"content":"一步步看Kfka 直接调用接口的弊端 系统耦合度提升 当生产者的生产速度大于消费者的消费速度时会导致消费者来不及处理导致消息丢失 消费者添加消息队列实现消息缓冲 很容想到在消费者中提供一个消息队列缓冲没有能够及时处理的消息，通过offset记录已经处理的消息。但这样做仍然会存在以下问题：\n在消费者重启后消息会丢失 每个消费者都维护一个消息队列存在着重复造轮子的问题 生产者和消费者耦合的问题并没有解决 将消息队列独立成一个服务 将消息队列抽成一个单独的服务使其可以服务于各个业务避免了重复造轮子的问题，实现了生产者和消费者之间的解耦，并且消息持久化、防止消息丢失的逻辑都可在一个服务中实现，独立于业务逻辑。在消息队列服务中我们需要实现高性能、高扩展。\n实现消息队列的高性能展性 根据topic定义多消息队列 通过增加生产者和消费者可以增加生产消息和消费消息的速度。单个消息队列将导致生产者和消费者竞争同一个队列，消息队列将成功性能的瓶颈。但不同业务下的消息并没有关联，也自然没有必要将所有的消息都通过一个消息队列处理。将同一个业务定义下的消息归纳到一个消息队列下（topic队列），这样就将消息队列中的一个消息队列拆分为多个topic队列，大大提升了消息的处理速度。\n当一个topic消息量大时，当前的设计仍然无法满足高性能需求。\n使用partition进一步提高并发度 对同一个topic再进行切分，每个partition对应着一个队列，不同消费者处理不同的消息队列。\nconsumer-group: 实现多消费者的业务隔离 在上面提到的优化策略中，多个消费者协作处理一个topic，也就是一个消息只能被一个消费者消费。在实际业务需求中，同一个消息需要被多个业务线处理，这样就引入了消费者组的概念，同一个消费者组中的消费者协作处理同一个消息（一个消息只能被消费者组中的一个消费者处理），不同消费者组互不影响。\n实现消息队列的高扩展性 在上面的步骤中，通过对消息队列切分再切分已经大大提高了消息队列的性能，但整个消息队列的性能仍受机器的限制，需要通过扩展机器提高整个消费队列服务的性能。\n通过将同一个topic中的不同partition分布在不同的broker上，再将多个broker构成一个kafka集群，实现硬件能力的扩展，提高kafka的处理速度。\n实现消息队列的高可用 解决单个broker宕机：一主多从 对每个partition，创建一个主节点，多个从节点，主节点负责读写，从节点只负责从主节点拉取数据、作数据备份。当某个broker宕机后，重新选取partition作为主节点。\n解决所有broker宕机：数据持久化与过期策略 如果数据都存储在内存中，当所有broker都宕机后未消费的消息将丢失，通过持久化并重启服务可实现服务宕机后的数据恢复。数据不断写入磁盘将会导致磁盘空间占满，需要一种过期策略剔除过期数据。\nKafka基本操作 ","date":"2025-01-27T00:28:09+08:00","image":"https://zhaoyifengf.github.io/p/kafka-introduction/cover_hu_45908159d335e9f2.png","permalink":"https://zhaoyifengf.github.io/p/kafka-introduction/","title":"Kafka Introduction"},{"content":"git版本控制的方式 两种版本控制方式 基于差异的版本控制（delta-based） 这类版本控制将存储信息看作一组基本文件和每个文件随时间逐步积累的差异\n基于快照的版本控制 这类版本控制将存储信息看作对小型文件系统的一系列快照，在git中，每当提交更新或者保存项目状态时，就会基本上对当时的全部文件创建一个快照保存并保存这个快照的索引。\ngit环境配置 基本命令 设置全局配置\n1 git config --global config：表示配置git \u0026ndash;global：表示全局配置 设置用户名\n1 git config --global user.name \u0026#34;用户名\u0026#34; 设置邮箱\n1 git config --global user.email \u0026#34;邮箱\u0026#34; 用户名和邮箱是这台机器上git的唯一标志\n获取git仓库 本地仓库的创建和初始化 在已存在目录中创建和初始化 进入目录\n1 cd 目录名 初始化当前目录\n1 git init 执行git init目录后出现如下结果：\n1 2 3 4 5 6 7 8 9 10 11 zhaoyifeng@MacBook-Air-6 test % git init 提示：使用 \u0026#39;master\u0026#39; 作为初始分支的名称。这个默认分支名称可能会更改。要在新仓库中 提示：配置使用初始分支名，并消除这条警告，请执行： 提示： 提示：\tgit config --global init.defaultBranch \u0026lt;名称\u0026gt; 提示： 提示：除了 \u0026#39;master\u0026#39; 之外，通常选定的名字有 \u0026#39;main\u0026#39;、\u0026#39;trunk\u0026#39; 和 \u0026#39;development\u0026#39;。 提示：可以通过以下命令重命名刚创建的分支： 提示： 提示：\tgit branch -m \u0026lt;name\u0026gt; 已初始化空的 Git 仓库于 /Users/zhaoyifeng/Documents/LocalRepository/test/.git/ 查看仓库中的文件夹：\n1 2 zhaoyifeng@MacBook-Air-6 test % ls -ah .\t..\t.git .git文件夹默认处于隐藏状态，需要添加-ah参数才能查看所有文件\n查看.git文件夹中的内容\n1 2 3 zhaoyifeng@MacBook-Air-6 test % cd .git zhaoyifeng@MacBook-Air-6 .git % ls -ah .\t..\tHEAD\tconfig\tdescription\thooks\tinfo\tobjects\trefs 文件夹 作用 hooks 包含客户端或服务端的勾子脚本 info 保护一个全局性排除文件 logs 保存日志信息 objects 存储所有数据内容 refs 存储指向数据的提交对象的指针 config 包含项目特有的配置选项 description 用来显示对仓库的描述 HEAD 指示目前被检出的分支 index 保存暂存区信息 git中的工作区、暂存区、版本库和仓库中文件夹的对应关系 git中的区域 文件夹 工作区 项目目录 版本库 .git文件夹，用来存放代码及历史版本 暂存区 .git下的index文件，用来存储临时文件（只是在index文件中添加一条操作记录，并没有将内容存放到index文件中） 克隆现有的仓库 git克隆命令：git clone \u0026lt;url\u0026gt; name 会将远程仓库中的项目克隆到当前目录，然后初始化该项目，并进行add和commit git中的文件状态 未跟踪\n默认情况下，git仓库（执行git init命令的文件夹）下的文件处于未跟踪的状态，git无法对区进行跟踪管理。通过add命令可以将其由未跟踪变为已跟踪状态。\n已跟踪 添加到git仓库管理中的文件处于已跟踪的状态，git可以对其进行跟踪管理。已跟踪状态可以细分为：\n已暂存（Staged）：通过add命令将文件添加到暂存区后文件将处于Staged状态。\n已修改（Modified）：修改了已跟踪的文件后，将处于Modified状态\n未暂存（Committed）：将暂存区中的文件使用commit命令提交到git仓库后将处于Modified状态。\n本地仓库的操作命令 创建本地仓库\n创建一个空文件夹 进入该文件夹执行git init命令 添加文件到本地仓库\n在创建的文件夹中新建一个文件 使用git add xxx.xx命令将工作区中的文件添加到暂存区，文件状态由未跟踪变为已跟踪。 1 2 3 zhaoyifeng@MacBook-Air-6 test % vim test.txt zhaoyifeng@MacBook-Air-6 test % git add test.txt 版本库只能跟踪和管理文本文件，视频、图片等文件虽然可由git管理，但git只能记录其大小而无法记录具体修改的内容。 git add .将所有文件添加到暂存区。 取消暂存：git reset HEAD 文件名：取消暂存某一文件 使git commit -m \u0026quot;xxxx\u0026quot;将暂存区中的内容提交到本地仓库，-m后面的参数是本次提交的描述 1 2 3 4 zhaoyifeng@MacBook-Air-6 test % git commit -m \u0026#34;第一次提交\u0026#34; [master（根提交） f9de3df] 第一次提交 1 file changed, 1 insertion(+) create mode 100644 test.txt 使用git commit -m -a进行先暂存再提交 在工作目录中回退到最近一次提交的版本：git checkout -- \u0026lt;file\u0026gt; 修改commit的注释 执行如下命令\n1 git commit --amend 进入编辑器，修改注释信息\n修改后输入 control + o 然后输入输入回车进行写入\n退出编译器\n忽略文件 新建.gitignore文件，在里面添加需要忽略的文件\n查看历史提交记录和当前状态 执行git status命令查看状态，使用git status -s或git status --short查看简短的状态。\n1 2 3 4 zhaoyifeng@MacBook-Air-6 test % git status 位于分支 master 无文件要提交，干净的工作区 zhaoyifeng@MacBook-Air-6 test % 执行git log查看历史记录\n1 2 3 4 5 zhaoyifeng@MacBook-Air-6 test % git log commit bbf9be55393f4aaeb85909b9b4071973d21a2d50 (HEAD -\u0026gt; master) Author: zhaoyifeng \u0026lt;zhaoyifeng@lixiang.com\u0026gt; Date: Wed Jul 5 17:14:36 2023 +0800 The first time submit commit后面的字符串是这次提交的ID，（HEAD -\u0026gt; master)表示当前提交到了主分支，HEAD是一个指针\nAuthor后面提交用户的信息\nDate是提交时间\n最后一行是提交的描述信息\n查看差异\ngit diff：查看尚未暂存的文件进行了那些修改 git diff -- staged：对比已暂存文件和最后一次提交文件的差异 git中的分支 分支的本质 分支的本质：指向commit对象的可变指针（也可理解为执行数据快照的指针）\ncommit对象：每次提交时都会保存一个commit对象，，包含指向暂存内容快照的指针、本次提交的作者等相关附属信息、零个或多个指向该提交对象的父对象指针：首次提交是没有直接祖先的，普通提交有一个祖先，由两个或多个分支合并产生的提交则有多个祖先。\ngit分支：指向commit对象的指针。git会默认创建一个master分支，在每次提交时都会自动向前移动。\n创建分支：本质上就是创建一个指针，git branch testing新建一个分支指针指向当前commit对象。也就是HEAD指针指向的分支指向的commit对象。\nHEAD指针：指向当前所在的分支（HEAD不可直接指向commit对象）\n切换分支：改变HEAD指向的分支。git checkout testing切换到testing分支。\n当你切换分支的时候，Git 会重置你的工作目录，使其看起来像回到了你在那个分支上最后一次提交的样子。 Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样。\n每提交一次后，HEAD都会随着当前分支一起移动。（HEAD指向的是分支指针，提交时分支指针不变，改变的只是分支指针指向的对象。）执行：\n1 2 vim test rb git commit -a -m \u0026#39;made a change\u0026#39; 得到如下结果： 切换到一个分支时会将工作目录中的内容加载为该分支指向的快照中的内容，这会导致原来的工作目录中的内容丢失。\n分支分叉：如果切换到master分支并在修改后进行提交那就会产生分支的分叉。\n1 2 3 git checkout master vim test rb git commit -a -m \u0026#39;made other change\u0026#39; 分支的合并：\n未分叉分支的合并\n执行如下命令：\n1 2 3 4 5 6 $ git checkout master $ git merge hotfix Updating f42c576..3a0874c Fast forward README | 1 - 1 files changed, 0 insertions(+), 1 deletions(-) 可以发现出现了Fast forward也就是快进，这是因为要合并的分支在master的上游，只需要把master指向hotfix指向的commit对象即可。\n分叉分支的合并 合并如图所示的分支，将iss53合并回master，执行如下命令\n1 2 git checkout master git merge iss53 由于master指向的commit节点（C4）不是iss53指向的commit节点（C5）的直接祖先，因此会进行C4、C5和二者最近的共同祖先（C2）三个节点的简单三方合并的到一个新的简单快照，然后创建一个行的commit对象（C6）指向这个简单快照，然后master指向C6。\n三种不同的合并方式\ngit merge \u0026ndash;ff(fast-forward): 如果能快进则快进分支即移动指针\ngit merge \u0026ndash;no-ff(no-fast-forword): 即使能快进也会创建一个新的commit(内容和被合并分支的commit相同)\ngit merge \u0026ndash;squash: 将被合并节点的修改的内容（保存删除操作）加载到工作区和暂存区，等待一次新的提交\n合并时发生冲突：如果不同分支修改了同一部分，那合并时可能发生冲突。\n1 2 3 4 git merge iss53 Auto-merging index.html CONFLICT (content): Merge conflict in index.html Automatic merge failed; fix conflicts and then commit the result. git作了合并但未提交，它会停下来等待解决冲突。打开发生冲突的文件index.html：\n1 2 3 4 5 6 7 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD:index.html \u0026lt;div id=\u0026#34;footer\u0026#34;\u0026gt;contact : email.support@github.com\u0026lt;/div\u0026gt; ======= \u0026lt;div id=\u0026#34;footer\u0026#34;\u0026gt; please contact us at support@github.com \u0026lt;/div\u0026gt; \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; iss53:index.html =======上面是当前分支文件中的内容，下面是iss53分支的内容。手动解决冲突，然后执行git add index.html，一旦进入暂存区就代表冲突已解决。再执行git commit。\n删除分支：git branch -d 分支名，删除指定的分支。\n分支的管理 查看当前有哪些分支，其中*表示当前分支即HEAD指向的分支git branch\n1 2 3 zhaoyifeng@MacBook-Air-6 test % git branch * master testing 查看分支最后一次提交的信息git branch -v\n1 2 3 zhaoyifeng@MacBook-Air-6 test % git branch -v * master e13db42 Merge branch \u0026#39;testing\u0026#39; testing ad69ccd testing第四次提交 查看已合并到当前分支的分支：git branch --merged\n查看未合并到当前分支的分支：git branch --no-merged\n远程分支\n远程仓库的添加与查看\n添加远程仓库，url是远程仓库的地址，shorname是给url对应的远程仓库的命名。执行git clone url后会自动添加一个远程仓库并将其命名为origin，并且克隆这个远程仓库到本地。\n1 git remote add \u0026lt;shortname\u0026gt; \u0026lt;url\u0026gt;\t查看远程仓库\n1 2 zhaoyifeng@MacBook-Air-6 mytest % git remote origin 查看远程仓库和对应的URL，fetch表示拉取的链接，push表示推送的链接。\n1 2 3 zhaoyifeng@MacBook-Air-6 mytest % git remote -v origin\thttps://gitee.com/zhao-jufeng/mytest/ (fetch) origin\thttps://gitee.com/zhao-jufeng/mytest/ (push) 查看某个远程仓库的具体信息\n1 2 3 4 5 6 7 8 9 10 11 12 zhaoyifeng@MacBook-Air-6 mytest % git remote show origin * 远程 origin 获取地址：https://gitee.com/zhao-jufeng/mytest/ 推送地址：https://gitee.com/zhao-jufeng/mytest/ HEAD 分支：master 远程分支： dev 已跟踪 master 已跟踪 为 \u0026#39;git pull\u0026#39; 配置的本地分支：ƒ master 与远程 master 合并 为 \u0026#39;git push\u0026#39; 配置的本地引用： master 推送至 master (最新) 远程分支的查看：远程分支是存储在本地对应着远程数据库中分支的分支。\ngit branch：只能查看本地分支\ngit branch -r：查看远程分支\n远程仓库含有master和dev分支，执行git clone https://gitee.com/zhao-jufeng/mytest/命令后执行git branch -r可以得到： zhaoyifeng@MacBook-Air-6 mytest % git branch -r origin/HEAD -\u0026gt; origin/master origin/dev origin/master 可以看到有两个远程分支，origin是远程仓库的名字，执行clone命令时默命名为origin。需要注意的是，这些分支也存储在本地，与远程仓库作一一映射。\n执行tree .git查看.git的目录结构：\n``` zhaoyifeng@MacBook-Air-6 mytest % tree .git .git ├── HEAD ├── config ├── description ├── hooks │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── fsmonitor-watchman.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── pre-merge-commit.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ ├── pre-receive.sample │ ├── prepare-commit-msg.sample │ ├── push-to-checkout.sample │ ├── sendemail-validate.sample │ └── update.sample ├── index ├── info │ └── exclude ├── logs │ ├── HEAD │ └── refs │ ├── heads │ │ └── master │ └── remotes │ └── origin │ └── HEAD ├── objects │ ├── info │ └── pack │ ├── pack-d93bb5ea2faba296524bc440149ae8b102f490cf.idx │ ├── pack-d93bb5ea2faba296524bc440149ae8b102f490cf.pack │ └── pack-d93bb5ea2faba296524bc440149ae8b102f490cf.rev ├── packed-refs └── refs ├── heads │ └── master ├── remotes │ └── origin │ └── HEAD └── tags ``` 远程的refs中的内容被压缩到了packed-refs中，查看其内容可以看到两个远程分支。 cat .git/packed-refs # pack-refs with: peeled fully-peeled sorted 7eb1322ce1fa2104ac76d996c08eb1a861860cc1 refs/remotes/origin/dev 7eb1322ce1fa2104ac76d996c08eb1a861860cc1 refs/remotes/origin/master 如果refs中含有远程分支，则该分支是最新的，packed-refs对远程分支的压缩有延迟。 执行git log可以查看历史，master, origin/master, origin/dev, origin/HEAD都指向了一个commit对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 zhaoyifeng@MacBook-Air-6 mytest % git log commit 7eb1322ce1fa2104ac76d996c08eb1a861860cc1 (HEAD -\u0026gt; master, origin/master, origin/dev, origin/HEAD) Author: 赵已峰 \u0026lt;zhaoyifeng@lixiang.com\u0026gt; Date: Fri Jul 7 01:25:14 2023 +0000 add test.txt. Signed-off-by: 赵已峰 \u0026lt;zhaoyifeng@lixiang.com\u0026gt; commit d6ce159ed51c87cd4e7531dfbbeb6015e5c22f1f Author: 赵已峰 \u0026lt;zhaoyifeng@lixiang.com\u0026gt; Date: Fri Jul 7 01:24:38 2023 +0000 Initial commit 同步远程仓库中的分支到本地：在远程分支（本地存储的远程仓库的分支并不是远程仓库中的分支）上修改后提交或者执行merge命令不会移动远程分支，只有通过git fetch或者git pull才会改变远程分支。这是为了保持远程分支和远程仓库中的分支的对应关系，避免在本地对远程分支进行修改。\ngit fetch [remote-name]：从远程仓库中拉取本地仓库没有的数据，这个操作会移动远程分支。\n1 2 3 4 5 6 7 8 zhaoyifeng@MacBook-Air-6 mytest % git fetch remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0 展开对象中: 100% (3/3), 967 字节 | 193.00 KiB/s, 完成. 来自 https://gitee.com/zhao-jufeng/mytest 7eb1322..f20bd41 master -\u0026gt; origin/master git pull ：git fetch和git merge命名的组合\n1 git pull 远程仓库名 远程仓库分支名:本地分支名 拉取远程仓库中的分支在与本地分支merge（需要注意的是这会拉取远程仓库中的所有分支） 如何入当前分支合并则可以省略本地分支名，简写为：\n1 git pull 远程仓库名 远程仓库分支名 删除远程分支：\n删除远程仓库中的分支再查看会出现如下提示：\n1 2 3 4 5 6 7 8 9 10 11 12 zhaoyifeng@MacBook-Air-6 mytest % git remote show origin * 远程 origin 获取地址：https://gitee.com/zhao-jufeng/mytest/ 推送地址：https://gitee.com/zhao-jufeng/mytest/ HEAD 分支：master 远程分支： master 已跟踪 refs/remotes/origin/dev 已过期（使用 \u0026#39;git remote prune\u0026#39; 来移除） 为 \u0026#39;git pull\u0026#39; 配置的本地分支： master 与远程 master 合并 为 \u0026#39;git push\u0026#39; 配置的本地引用： master 推送至 master (本地已过时) 提示远程分支已过期，建议删除。执行如下命名删除：\n1 2 3 4 zhaoyifeng@MacBook-Air-6 mytest % git remote prune origin 修剪 origin URL：https://gitee.com/zhao-jufeng/mytest/ * [已删除] origin/dev 或者git fetch --prune先删远程仓库中没有的本地远程分支，然后再拉取远程仓库中的数据。\n本地仓库同步到远程仓库\ngit push 远程仓库名 本地分支名:远程仓库中的分支名：用本地仓库中的分支更新远程仓库的分支，这会让远程仓库的分支直接指向本地仓库的分支指向的commit，此外，与远程仓库中对应的远程分支也会指向本地分支指向的commit。注意，这并不要本地仓库中有远程仓库中对应的远程分支。\n如果本地分支名与远程仓库中的分支名相同，则可以简写为git push 远程仓库名 分支名\n跟踪分支：执行git push命令时需要同指定远程仓库名、本地分支名和远程分支名，而跟踪分支则可简化这个操作。\n跟踪分支：本地分支和某个远程分支建立联系后那这个本地分支就变成一个跟踪分支。在跟踪分支上执行git push和git pull命令时无需指定远程仓库名、本地分支名和远程分支名。\n跟踪分支的创建\n在远程分支上创建分支时指定其为远程分支（建的本地分支名与远程分支名相同）：$ git checkout --track 远程仓库名/远程分支名\n在远程分支上创建分支时指定其为远程分支（指定本地分支名）：git checkout -b 本地分支名 远程仓库名/远程分支名\n指定已有的本地分支为莫哥远程分支的跟踪分支：git branch -u 远程仓库名/远程分支名\ngit中的标签 什么是标签 标签的本质：一个指向commit对象的指针，类似于分支，但标签是一个静态指针，不会移动。 标签的作用：标记一个重要的commit。 打标签 给当前分支指向的commit打标签\n轻量标签：git tag 标签名 附注标签：git tag -a 标签名 -m \u0026quot;描述信息\u0026quot;，相比轻量标签，附注标签可以添加描述信息 给某一次commit打标签：只需要在上面两种打标签的方式最后面添加要打标签的commit的Hash值即可\n查看标签\n查看有哪些标签git tag 查看某一条标签的信息git show 标签名 ","date":"2025-01-03T22:04:00Z","image":"https://zhaoyifengf.github.io/p/git-introduction/cover_hu_2000f2c82405780b.png","permalink":"https://zhaoyifengf.github.io/p/git-introduction/","title":"Git Introduction"},{"content":"mybatisplus SQL执行流程 服务启动时通过自动配置类创建MybatisSqlSessionFactoryBean mybatis-plus-boot-starter包提供了MybatisPlusAutoConfiguration自动配置类，该自动配置类创建了MybatisSqlSessionFactoryBean对象并交由Spring管理，在创建MybatisSqlSessionFactoryBean时，sqlSessionFactory方法设置了DataScoure对象。自动配置类需要满足以下几个条件才会创建MybatisSqlSessionFactoryBean：\nMybatisPlusAutoConfiguration上的@ConditionalOnSingleCandidate指定了：被Spring管理的只有一个DataSource对象或者多个DataSource对指定了优先级（如通过@Primary注解指定） sqlSessionFactory方法上@ConditionalOnMissingBean指定了：只有在不存在SqlSessionFactory时才会创建MybatisSqlSessionFactoryBean对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Configuration(proxyBeanMethods = false) @ConditionalOnClass({SqlSessionFactory.class, SqlSessionFactoryBean.class}) @ConditionalOnSingleCandidate(DataSource.class) @EnableConfigurationProperties(MybatisPlusProperties.class) @AutoConfigureAfter({DataSourceAutoConfiguration.class, MybatisPlusLanguageDriverAutoConfiguration.class}) public class MybatisPlusAutoConfiguration implements InitializingBean { @Bean @ConditionalOnMissingBean public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception { // TODO 使用 MybatisSqlSessionFactoryBean 而不是 SqlSessionFactoryBean MybatisSqlSessionFactoryBean factory = new MybatisSqlSessionFactoryBean(); factory.setDataSource(dataSource); ..... } } Spring对事务进行代理 执行Mybatisplus DML语句前，Spring对要执行的方法（加了@Transactiontional注解）进行代理，代理执行的逻辑在TransactionAspectSupport中的invokeWithinTransaction方法中。整体调用流程如下\nTransactionInterceptor#invoke -\u0026gt; TransactionAspectSupport#invokeWithinTransaction执行开启事务、执行业务逻辑、提交事务三个步骤。\n开启事务 TransactionAspectSupport#invokeWithinTransaction -\u0026gt; determineTransactionManager TransactionAspectSupport#determineTransactionManager -\u0026gt; createTransactionIfNecessary TransactionAspectSupport#createTransactionIfNecessary -\u0026gt; AbstractPlatformTransactionManager#getTransaction，getTransaction方法先尝试获取事务再开启事务： 获取事务 AbstractPlatformTransactionManager#getTransaction -\u0026gt; DataSourceTransactionManager#doGetTransaction（doGetTransaction是个抽象方法，具体逻辑由实现类提供，我们在这里只讨论DataSourceTransactionManager的实现逻辑） DataSourceTransactionManager#doGetTransaction，该方法做下如下操作： 创建DataSourceTransactionObject对象 TransactionSynchronizationManager.getResource方法获取DataSourceTransactionManager中dataScoure对象绑定的ConnectionHolder对象（用来存储connection对象）。TransactionSynchronizationManager中维护了一个ThreadLocal属性resources，这是一个以dataScoure对象为key、ConnectionHolder对象为值的Map。TransactionSynchronizationManager用来管理每个线程中和dataScoure对象绑定的connection对象。 将上一步获取的ConnectionHolder设置到DataSourceTransactionObject中 开启事务 AbstractPlatformTransactionManager#getTransactio -\u0026gt; DataSourceTransactionManager#startTransaction DataSourceTransactionManager#startTransactionn -\u0026gt; doBegin方法，实现如下操作（DataSourceTransactionManager#doGetTransaction对象返回的DataSourceTransactionObject中的ConnectionHolder为空时执行该步骤）： 通过DataSourceTransactionManager中dataScoure对象获取connection 将connection包装为ConnectionHolder对象 通过TransactionSynchronizationManager.bindResource将ConnectionHolder对象和connection对象绑定并设置上面提到的TransactionSynchronizationManager中的ThreadLocal属性resources中 执行业务逻辑 TransactionAspectSupport#invokeWithinTransaction执行被代理方法，mybatisplus中的方法也会在在此被执行，具体流程我们方法下一个部分讨论。 提交事务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 @SuppressWarnings(\u0026#34;serial\u0026#34;) public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable { @Override @Nullable public Object invoke(MethodInvocation invocation) throws Throwable { // Work out the target class: may be {@code null}. // The TransactionAttributeSource should be passed the target class // as well as the method, which may be from an interface. Class\u0026lt;?\u0026gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // Adapt to TransactionAspectSupport\u0026#39;s invokeWithinTransaction... return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed); } } public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean { @Nullable protected Object invokeWithinTransaction(Method method, @Nullable Class\u0026lt;?\u0026gt; targetClass, final InvocationCallback invocation) throws Throwable { // If the transaction attribute is null, the method is non-transactional. TransactionAttributeSource tas = getTransactionAttributeSource(); final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); final TransactionManager tm = determineTransactionManager(txAttr); ........ // 响应式事务处理逻辑 PlatformTransactionManager ptm = asPlatformTransactionManager(tm); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(ptm instanceof CallbackPreferringPlatformTransactionManager)) { // Standard transaction demarcation with getTransaction and commit/rollback calls. TransactionInfo txInfo = createTransactionIfNecessary(ptm, txAttr, joinpointIdentification); Object retVal; try { // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. retVal = invocation.proceedWithInvocation(); } catch (Throwable ex) { // target invocation exception completeTransactionAfterThrowing(txInfo, ex); throw ex; } finally { cleanupTransactionInfo(txInfo); } if (retVal != null \u0026amp;\u0026amp; vavrPresent \u0026amp;\u0026amp; VavrDelegate.isVavrTry(retVal)) { // Set rollback-only in case of Vavr failure matching our rollback rules... TransactionStatus status = txInfo.getTransactionStatus(); if (status != null \u0026amp;\u0026amp; txAttr != null) { retVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status); } } commitTransactionAfterReturning(txInfo); return retVal; }else { ...... // 非回调事务处理逻辑 } protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) { ........... TransactionStatus status = null; if (txAttr != null) { if (tm != null) { status = tm.getTransaction(txAttr); } ....... } ........... } } public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable { @Override public final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException { ........................... Object transaction = doGetTransaction(); boolean debugEnabled = logger.isDebugEnabled(); // No existing transaction found -\u0026gt; check propagation behavior to find out how to proceed. if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) { ............. } else if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) { SuspendedResourcesHolder suspendedResources = suspend(null); ............... try { return startTransaction(def, transaction, debugEnabled, suspendedResources); } catch (RuntimeException | Error ex) { } } else { ......... } } /** * Start a new transaction. */ private TransactionStatus startTransaction(TransactionDefinition definition, Object transaction, boolean debugEnabled, @Nullable SuspendedResourcesHolder suspendedResources) { boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus( definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); doBegin(transaction, definition); prepareSynchronization(status, definition); return status; } } public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean { protected Object doGetTransaction() { DataSourceTransactionObject txObject = new DataSourceTransactionObject(); txObject.setSavepointAllowed(isNestedTransactionAllowed()); ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(obtainDataSource()); txObject.setConnectionHolder(conHolder, false); return txObject; } protected void doBegin(Object transaction, TransactionDefinition definition) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try { if (!txObject.hasConnectionHolder() || txObject.getConnectionHolder().isSynchronizedWithTransaction()) { Connection newCon = obtainDataSource().getConnection(); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Acquired Connection [\u0026#34; + newCon + \u0026#34;] for JDBC transaction\u0026#34;); } txObject.setConnectionHolder(new ConnectionHolder(newCon), true); } txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); txObject.setReadOnly(definition.isReadOnly()); // Switch to manual commit if necessary. This is very expensive in some JDBC drivers, // so we don\u0026#39;t want to do it unnecessarily (for example if we\u0026#39;ve explicitly // configured the connection pool to set it already). if (con.getAutoCommit()) { txObject.setMustRestoreAutoCommit(true); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Switching JDBC Connection [\u0026#34; + con + \u0026#34;] to manual commit\u0026#34;); } con.setAutoCommit(false); } prepareTransactionalConnection(con, definition); txObject.getConnectionHolder().setTransactionActive(true); int timeout = determineTimeout(definition); if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) { txObject.getConnectionHolder().setTimeoutInSeconds(timeout); } // Bind the connection holder to the thread. if (txObject.isNewConnectionHolder()) { TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder()); } } catch (Throwable ex) { if (txObject.isNewConnectionHolder()) { DataSourceUtils.releaseConnection(con, obtainDataSource()); txObject.setConnectionHolder(null, false); } throw new CannotCreateTransactionException(\u0026#34;Could not open JDBC Connection for transaction\u0026#34;, ex); } } } 执行mybatisplus DML与Select语句 以调用IService的saveBatch方法为例，其最初调用链路如下ServiceImpl#saveBatch -\u0026gt; ServiceImpl#executeBatch -\u0026gt; SqlHelper#executeBatch， 执行步骤如下：\n获取SqlSessionFactory\nSqlHelper#executeBatch调用sqlSessionFactory方法，sqlSessionFactory对象中持有DataSource对象的引用。\n调用上面一步获取的SqlSessionFactory的openSession方法（这里以DefaultSqlSessionFactory加以说明），需要注意的事这里的Transaction对象并不参与事务的执行，只是用来管理数据源，该方法执行了如下步骤：\n创建TransactionFactory对象 通过TransactionFactory对象创建Transaction对象，并传入从configure（SqlSessionFactory持有）对象中获取的dataScoure对象 创建Executor对象并传入Transaction对象 创建DefaultSqlSession对象并传入Executor对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\u0026#34;Error opening session. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } 调用SqlSession的insert方法\n调用链路SqlSession#insert -\u0026gt; SqlSession#update -\u0026gt; BaseExecutor#update -\u0026gt; BatchExecutor#doUpdate，BatchExecutor#doUpdate执行了如下步骤： 获取Connection，调用BaseExecutor#getConnection -\u0026gt; Transaction.getConnection -\u0026gt; SpringManagedTransaction.getConnection -\u0026gt; SpringManagedTransaction.openConnection -\u0026gt; DataSourceUtils.getConnection -\u0026gt; DataSourceUtils.doGetConnection，从下面的代码可知道如果当前数据源绑定了Connection则获取绑定的Connection，如果没有绑定则调用DataScoure对象的getConnection方法获取新的connection方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public static Connection doGetConnection(DataSource dataSource) throws SQLException { ....... ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource); if (conHolder != null \u0026amp;\u0026amp; (conHolder.hasConnection() || conHolder.isSynchronizedWithTransaction())) { conHolder.requested(); if (!conHolder.hasConnection()) { logger.debug(\u0026#34;Fetching resumed JDBC Connection from DataSource\u0026#34;); conHolder.setConnection(fetchConnection(dataSource)); } return conHolder.getConnection(); } // Else we either got no holder or an empty thread-bound holder here. logger.debug(\u0026#34;Fetching JDBC Connection from DataSource\u0026#34;); Connection con = fetchConnection(dataSource); ........ return con; } private static Connection fetchConnection(DataSource dataSource) throws SQLException { Connection con = dataSource.getConnection(); if (con == null) { throw new IllegalStateException(\u0026#34;DataSource returned null from getConnection(): \u0026#34; + dataSource); } return con; } 准备Statement，设置Connection为上一步获取的Connection 执行SQL语句 DataScoure：数据库链接的管理者 不论是在Spring事务还是mybatisplus执行SQL语句前获取connection，都会调用DataScoure#getConnection方法。如下，DataScoure只提供了两个获取connection方法，由此可知DataScoure最主要的功能就是进行Connection的管理。对DataSource的getConnection方法提供不同的实现可以提供不同的功能，最典型的莫过于连接池和动态数据源。\n1 2 3 4 5 6 public interface DataSource extends CommonDataSource, Wrapper { Connection getConnection() throws SQLException; Connection getConnection(String username, String password) throws SQLException; } 连接池 我们以HikariCP为例，先介绍其在SpringBoot项目中如何使用，再介绍如何通过其获取Connection\nSpringBoot集成HikariCP\nyaml配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 spring: datasource: type: com.zaxxer.hikari.HikariDataSource url: jdbc:mysql://localhost:3306/test?useSSL=false username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver hikari: pool-name: MyHikariCP minimum-idle: 5 maximum-pool-size: 20 idle-timeout: 600000 max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 数据源属性类 1 2 3 4 5 6 7 8 9 10 11 @ConfigurationProperties(prefix = \u0026#34;spring.datasource\u0026#34;) public class DataSourceProperties implements BeanClassLoaderAware, InitializingBean { private ClassLoader classLoader; private String name; private boolean generateUniqueName = true; private Class\u0026lt;? extends DataSource\u0026gt; type; private String driverClassName; private String url; private String username; private String password; } Springboot自动配置\n当我们在yaml文件中指定了type: com.zaxxer.hikari.HikariDataSource满足了自动配置类@ConditionalOnProperty(name = \u0026quot;spring.datasource.type\u0026quot;, havingValue = \u0026quot;com.zaxxer.hikari.HikariDataSource\u0026quot;,matchIfMissing = true)的条件，创建HikariDataSource对象并交由Spring管理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 stract class DataSourceConfiguration { @Configuration(proxyBeanMethods = false) @ConditionalOnClass(HikariDataSource.class) @ConditionalOnMissingBean(DataSource.class) @ConditionalOnProperty(name = \u0026#34;spring.datasource.type\u0026#34;, havingValue = \u0026#34;com.zaxxer.hikari.HikariDataSource\u0026#34;, matchIfMissing = true) static class Hikari { @Bean @ConfigurationProperties(prefix = \u0026#34;spring.datasource.hikari\u0026#34;) HikariDataSource dataSource(DataSourceProperties properties) { HikariDataSource dataSource = createDataSource(properties, HikariDataSource.class); if (StringUtils.hasText(properties.getName())) { dataSource.setPoolName(properties.getName()); } return dataSource; } } } HikariDataSource实现数据库链接管理 在没有创建其他数据源的情况下，HikariDataSource会被注入Mybatisplus的MybatisSqlSessionFactoryBean并在执行SQL语句前被获取，HikariDataSource只需要重写getConnection方法就可实现对数据库连接的管理。如下代码，HikariDataSource获取数据库连接的功能最终委托给了HikariPool。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 public class HikariDataSource extends HikariConfig implements DataSource, Closeable { private static final Logger LOGGER = LoggerFactory.getLogger(HikariDataSource.class); private final AtomicBoolean isShutdown = new AtomicBoolean(); private final HikariPool fastPathPool; private volatile HikariPool pool; public HikariDataSource() { super(); fastPathPool = null; } public HikariDataSource(HikariConfig configuration) { configuration.validate(); configuration.copyStateTo(this); LOGGER.info(\u0026#34;{} - Starting...\u0026#34;, configuration.getPoolName()); pool = fastPathPool = new HikariPool(this); LOGGER.info(\u0026#34;{} - Start completed.\u0026#34;, configuration.getPoolName()); this.seal(); } @Override public Connection getConnection() throws SQLException { if (isClosed()) { throw new SQLException(\u0026#34;HikariDataSource \u0026#34; + this + \u0026#34; has been closed.\u0026#34;); } if (fastPathPool != null) { return fastPathPool.getConnection(); } // See http://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java HikariPool result = pool; if (result == null) { synchronized (this) { result = pool; if (result == null) { validate(); LOGGER.info(\u0026#34;{} - Starting...\u0026#34;, getPoolName()); try { pool = result = new HikariPool(this); this.seal(); } catch (PoolInitializationException pie) { if (pie.getCause() instanceof SQLException) { throw (SQLException) pie.getCause(); } else { throw pie; } } LOGGER.info(\u0026#34;{} - Start completed.\u0026#34;, getPoolName()); } } } return result.getConnection(); } } HikariPool核心代码如下，\n动态数据源 (待补充) 编译时动态 运行时动态 mybatisplus 执行 SQL时数据源问题总结 数据源DataScoure是一个管理数据库连接的对象，它与数据库连接是一对多的关联 mybatisplus的数据源对象取自SqlSessionFactory对象，在满足第一节Mybatisplus自动配置MybatisSqlSessionFactoryBean的条件下，mybatisplus获取的是优先级最高的（加了@Primary）DataScoure对象 指定事务管理器的数据源只会影响@Transactional注解绑定Datasource对象和Connection方法的逻辑，并不会影响mybatisplus实际获取的数据源（mybatisplus从SqlSessionFactory中取数据源） ","date":"2025-06-23T23:26:52+08:00","permalink":"https://zhaoyifengf.github.io/p/mybatisplus%E4%B8%8Edatasource/","title":"Mybatisplus与DataSource"}]