[{"content":"分布式事务基本概念 分布式系统架构演进 单体应用架构 在单体应用架构下所有功能都被打包成一个服务并部署，这种架构具有如下优点：\n架构简单、项目开发和维护成本低 所有项目部署在一起，方便维护。 但单体应用架构也存在诸多缺陷：\n所有模块耦合在一起，不容易开发和维护（合并分支需要解决冲突，大项目启动事件长） 项目模块过于耦合，一个模块出问题可能导致整个项目不可用 无法针对某个具体模块提升性能（所有的模块都部署在一起，无法针对单个模块进行水平扩展） 无法对项目进行水平扩展（项目大启动时间长，项目部署低效） 垂直应用架构 垂直应用架构将系统按照业务领域进行拆分，当有业务领域流量增大只需要针对单个业务领域增加节点，无需对整个项目增加服务器节点。该架构具有如下优点：\n可以针对不同系统进行优化 能够实现水平扩展 各系统能够分担流量，减小并发度 系统与系统隔离，单系统出现故障不影响其他系统运行 垂直应用架构仍然存在如下缺点：\n拆分后的系统之间相互独立，无法进行相互调用 拆分粒度大，重复代码片段多，会出现重复开发与难以维护的问题 分布式架构 分布式架构在垂直架构的基础上，将重复的代码抽出来独立未单独的服务。整个系统被拆分为服务层和表现层，表现层负责处理与页面的交互，服务层则封装了具体的业务逻辑供表现层调用。这种架构具有如下优点：\n提高了代码的服用程度，降低了维护成本。 可以针对服务进行性能优化。 但该架构具有如下缺点：\n系统之间的调用关系变得复杂 系统之间的依赖关系变得复杂 系统维护成本变高 SOA架构 SOA架构引入了注册中心解决了服务依赖与调用关系的自动注册与发现。但这种架构有如下缺点：\n各服务间存在依赖关系，如果某个服务出现故障可能会造成服务器崩溃。 服务间的依赖与调用关系复杂增加了测试和运维成本。 微服务架构 微服务架构与SOA架构相比有如下差异：\n服务大小：在SOA架构中，服务通常是大型的负责多个业务功能；微服务架构中服务负责的功能更具体，通常是某个业务的具体功能。 数据存储：在SOA架构个中服务共用同一个数据库；微服务每个服务通常拥有自己的数据库。 通信协议：SOA通常采用SOAP等复杂的通信协议；微服务通常采用REST或gRPC。 服务协调：SOA通常采用中心话的协调方式如ES；微服务通常采用去中心化的服务方式，如API网关。 部署方式：SOA通常集中部署；微服务一般进行单独部署。 在SOA架构中，服务通常是大型的负责多个业务功能，不同服务共用一个数据库，\n分布式事务场景 一个事务需要多个服务远程协作完成就会产生分布式事务问题，分布式事务会在三种场景下产生，分别是跨JVM进程、跨数据库实例、和多服务访问单数据库。\n跨JVM进程（多服务、多数据库） 跨数据库实例（单服务、多数据库） 和多服务访问单数据库（多服务、单数据库） 数据一致性 数据一致性问题包含多副本、调用超时、缓存与数据库不一致、多个缓存节点数据不一致等场景。\n调用超时场景 调用超时指的是A服务同步或者异步调用B服务超时，导致A服务与B服务数据不一致。\n缓存与数据库不一致 在高并发场景下，一些热点数据会缓存到Redis等组件中，此时如果对数据库中的数据进行写操作将会导致缓存中的数据与数据库中的数据不一致。\n多缓存节点数据不一致 缓存内部各节点数据不一致，如在Redis集群中，由于网络问题导致多个缓存节点数据不一致。\n分布式事务理论知识 CAP（Consistency、Availability、Partition Tolerance）理论 CAP理论：在分布式系统，不会同时具备CAP三个特性，只能同时具备其中两个。\n一致性\n用户对数据的写操作在所有数据副本要么都成功、要么都失败。\n可用性\n客户端访问数据时能够快速得到响应。\n分区容忍性\n分区：分布式系统中不同节点间通信出现了问题。分区容忍：在出现分区时系统仍然能对外提供服务。\n为什么CAP只能满足其中两个 首先需要明确的是一个分布式系统必需要满足分区容错，也就是CAP中的P。在分布式系统中分区是一定会出现的，没有人能够保证节点与节点之间的网络总是不出问题，也没有人能够保证单个节点始终运行正常。如果一个分布式系统出现分区整个系统就停止服务，那其与单体服务并无区别（分布式系统的初衷就是通过多节点部署来提高系统的可用性）。\n在出现分区的情况下，一致性与可用性只能满足其一：\n若要满足一致性，在对数据的多副本进行写入时需要锁定资源，而出现分区导致无法确认所有副本都写入成功，客户端的访问也无法在有效时间内得到响应。\n若要满足可可用性，对任意节点的访问都需要在指定时间得到响应，当被访问节点数据写入成功而存在节点数据未写入成功或者被访问节点数据未写入成功而其余节点数据写入成功则可用性也无法得到满足。\nBASE（Basically Available, Soft State， Eventually Consistent）理论 当出现分区时，BASE理论允许部分数据不可用，但会保证核心功能可用；允许数据在一定时间内不一致，但经过一段时间数据最终是一致的。\n基本可用\n基本可用指的是分布式系统出现故障时，允许损失部分可用性（比如响应时间或部分功能）\n软状态\n软状态指的是允许系统出现中间状态，但中中间状态不会影响系统的整体可用性。\n最终一致性\n最终一致性指的是允许允许数据在各个节点存在不一致，只需要数据最终一致。\n分布式事务解决方案 强一致性分布式事务解决方案 强一致性事务要求任意时刻参与全局事务的各个节点的数据都一致。\n强一致性事务的三种方案 全局事务模型（DTP） 基本概念\n事务：一个完整的工作单元，具备ACID特性 全局事务：事务管理器管理的全局事务，能一次操作多个资源管理器 分支事务：全局事务中的每个资源管理器中独立执行的事务 控制线程：执行全局事务的线程 执行流程 DTP模型中的三个核心组件：\nAP（应用程序、Application Program）：参与DTP分布式事务模型的应用程序。 RM（资源管理器、Resource Manager）：数据库管理系统或者消息服务管理器，用来对响应的资源进行有效的控制，相应的资源需要实现XA定义的接口。 TM（事务管理器、Transaction Manager）：负责协调和管理DTP模型中的事务，为应用程序提供编程接口，同时管理资源管理器。 二阶段提交模型（2PC） 2PC模型即两阶段提交协议模型，该模型将事务流程分为Prepare阶段和Commit阶段。\nPrepare阶段\n在Prepare阶段，事务管理器给每个参与全局事务的资源管理器发送Prepare消息，资源管理器要么返回失败，要么在本地执行相应的事务，将事务写入本地的Redo Log文件和Undo Log文件，但此时事务并未提交。\n如果在Prepare阶段有资源管理器返回了失败消息则在Commit阶段事务管理器会向其他响应正常消息发送回滚消息。\nCommit阶段\n在2PC的commit阶段，事务管理器向参与全局事务的资源管理器发送commit消息，资源管理器收到消息后提交本地事务并将提交成功的消息返回给事务管理器。\n三阶段提交模型（3PC） 相比与2PC模型，3PC模型将prepare阶段分成了CanCommit阶段与PreCommit阶段。\nCanCommit阶段 在CanCommit阶段，事务管理器会向资源管理器发送CanCommit消息，资源管理器如果认为可以执行任务则发送确认消息并进入预备状态。\nPreCommit阶段 在PreCommit阶段，资源管理器接受到消息并写入undo log与redo log。\nDoCommit阶段 在DoCommit阶段，资源管理器收到消息并提交事务。如果超过一定时间资源管理器没有收到事务管理器发送的事务回滚消息则会直接提交事务，如果其资源管理器收到了回滚消息则会导致数据不一致。\n最终一致性的三种解决方案 强一致性方案要求参与事务的各个节点的数据时刻保持一致，在高并发场景下会影响性能。最新一致性方案不要求各个节点的数据始终保持一致，只要数据最终一致即可。\n服务模式 可查询操作 可查询操作服务模型要求操作具有唯一标识（唯一业务标识及操作时间）并且要求其他服务在提供操作接口的情况下提供查询接口及批量查询接口，在分布式环境下可以通过查询接口确认操作是否我那次。\n幂等操作 幂等操作要求对于同一个方法相同的参数，操作一次和操作多次的结果相同。在分布式环境下，常常需要重试，而幂等可保证重试对最终结果没有影响。\nTCC操作 TCC模式包含Try，Commit，Cancel三个阶段。在try阶段完成所有业务的一致性检查、预留必要的业务资源，并需要与其他操作隔离。在Commit执行真正的业务操作。在Cancel释放预留的资源。\n可补偿操作 在分布式环境下数据可能出现不一致，这时需要通过补偿接口进行补偿。 在分布式环境下数据可能出现不一致，这时需要通过补偿接口进行补偿。\nTCC 方案 Try阶段 在 Try 阶段在具体的业务数据进行修改操作并标记状态为待提交，并记录此阶段的反向操作（如增加多少库存）\nConfirm阶段 如果 Try 阶段执行全部成功，则将待提交状态标记为提交状态并取消反向操作。\nCancel阶段 标记操作的具体业务数据状态为取消，并对业务数据进行反向操作，清除具体的反向操作。\n可靠消息最终一致性解决方案 事务发起方发送可靠消息，事务参与方从可靠消息服务接收消息。由于事务发起方和可靠消息服务、可靠消息服务和事务参与方之间都是通过网络进行通信的，所以需要引入消息确认服务和消息回复服务。\n消息确认服务会定期检测事务发起方业务的执行状态和消息库中的数据，如果发现事务发起方业务的执行状态与消息库中的数据不一致，消息确认服务就会同步事务发起方的业务数据和消息库中的数据，保证数据一致性。\n消息恢复服务会定期检测事务参与方业务执行状态与消息库中数据是否一致，如果发现不一致则回滚消息状态为事务发起方发送消息但未被事务参与方消费的状态。\n最大努力通知型解决方案 业务方在完成业务处理后，会向业务参与方发送消息，发送消息时通知时运行消息丢失。业务方需要体统查询接口供业务接收方按需查询，用于恢复丢失的消息。\n","date":"2025-02-10T22:34:00+08:00","image":"http://localhost:1313/p/distribution-transaction/cover_hu2746450985513901792.png","permalink":"http://localhost:1313/p/distribution-transaction/","title":"Distribution Transaction"},{"content":"利用倒排索引加速查询符合条件的文本 利用倒排索引加速查询 对于若干段文本，例如：1: \u0026ldquo;I hava an orange\u0026rdquo;，2: \u0026ldquo;I hava a banana\u0026rdquo;，3: \u0026ldquo;I hava an apple\u0026rdquo;，想要查询\u0026quot;apple\u0026quot;在哪条记录里需要遍历所有文体，时间复杂度为O(n)。将文本进行切分，以切分后的文本作为键，文本ID作为值构成一个二维表格，这样可以大大降低查询时间。\nterm 文本id I 1、2、3 have 1、2、3 an 1、3 a 2 orange 1 banana 2 apple 3 但当词项增多，遍历这些词项仍需花费大量时间，对词项进行倒排并进行二分查找可将时间复杂度降低到O(logN)。\nTerm dictionary Posting list a 2 an 1、3 apple 3 banana 2 have 1、2、3 I 1、2、3 orange 1 将排好的词项称为Term dictionary，文档ID称为Posting list，构成的搜索结构称为inverted index（倒排索引）。\n利用Term index进一步加速查询 将文本进行分词后得到的Term dictionary数据量巨大，只能通过磁盘检索。检索磁盘耗时较长，基于Term dictionary构建一颗字典树（Term index）并将字段树放入内存将极大加速索引效率。\n利用Store Fileds存储文档 ES采用行式存储数据，对应存储结构被称为Store Fileds。\n利用Doc Values实现快速聚合操作、排序、脚本计算 行式存储数据在进行大规模数据的聚合、排序以及脚本计算操作时效率低下，因此ES提供了列式存储结构Doc Values，针对单个字段进行集中存储，每行记录了字段值及其所在文档的文档ID。\nsegment segment是一个具备搜索功能的最小单元，包含了Inverted Index，Term Index，Stored Fileds，Doc Values四个模块。\nLucene 新增数据时不会立刻写入segment而是先写入内存缓冲区，等到执行refresh动作时将数据写入新的segment，在segment激活后才能参与搜索，已经写入的segment不可再进行写入。频繁的生成新的segment会导致数量过多，通过不定期将多个小segment合并为一个大segment可以减小segment数量。上面提到的就是大名鼎鼎的搜索引擎lucene的工作过程。\nES实现高性能、高并发、高扩展性 高性能 单个lucene读写性能过低，将数据按照业务划分，不同的数据写入不同的lucene可以提到读写并发度\n单个index name的数量扔热可能过多，对单个index name的数据进行分片，每个分片对应着一个lucene库，可进一步提高并发度。\n高扩展性 申请多个node，将不同的分片部署到不同的node上\n高可用 对每个分片部署多个副本，不同的副本部署到不同的节点上。\nnode请求分化 若同一个node同时负责集群管理、存储数据、处理请求，在进行扩展时将同时扩展这几个能力，在实际使用时可能只需要扩展其中一两个能力，通过将功能进行分化，不同的node部署不同的功能，可实现能力的按需扩展。\n去中心化 由于同时保护了多个node，需要对多个node进行管理选取其中主节点，使用zookeeper会导致系统过重，使用raft可实现去中心化选主。\nES 整体架构 ","date":"2025-02-10T22:34:00+08:00","image":"http://localhost:1313/p/es-introduction/cover_hu8373384276586675813.png","permalink":"http://localhost:1313/p/es-introduction/","title":"ES Introduction"},{"content":"一步步看Kfka 直接调用接口的弊端 系统耦合度提升 当生产者的生产速度大于消费者的消费速度时会导致消费者来不及处理导致消息丢失 消费者添加消息队列实现消息缓冲 很容想到在消费者中提供一个消息队列缓冲没有能够及时处理的消息，通过offset记录已经处理的消息。但这样做仍然会存在以下问题：\n在消费者重启后消息会丢失 每个消费者都维护一个消息队列存在着重复造轮子的问题 生产者和消费者耦合的问题并没有解决 将消息队列独立成一个服务 将消息队列抽成一个单独的服务使其可以服务于各个业务避免了重复造轮子的问题，实现了生产者和消费者之间的解耦，并且消息持久化、防止消息丢失的逻辑都可在一个服务中实现，独立于业务逻辑。在消息队列服务中我们需要实现高性能、高扩展。\n实现消息队列的高性能展性 根据topic定义多消息队列 通过增加生产者和消费者可以增加生产消息和消费消息的速度。单个消息队列将导致生产者和消费者竞争同一个队列，消息队列将成功性能的瓶颈。但不同业务下的消息并没有关联，也自然没有必要将所有的消息都通过一个消息队列处理。将同一个业务定义下的消息归纳到一个消息队列下（topic队列），这样就将消息队列中的一个消息队列拆分为多个topic队列，大大提升了消息的处理速度。\n当一个topic消息量大时，当前的设计仍然无法满足高性能需求。\n使用partition进一步提高并发度 对同一个topic再进行切分，每个partition对应着一个队列，不同消费者处理不同的消息队列。\nconsumer-group: 实现多消费者的业务隔离 在上面提到的优化策略中，多个消费者协作处理一个topic，也就是一个消息只能被一个消费者消费。在实际业务需求中，同一个消息需要被多个业务线处理，这样就引入了消费者组的概念，同一个消费者组中的消费者协作处理同一个消息（一个消息只能被消费者组中的一个消费者处理），不同消费者组互不影响。\n实现消息队列的高扩展性 在上面的步骤中，通过对消息队列切分再切分已经大大提高了消息队列的性能，但整个消息队列的性能仍受机器的限制，需要通过扩展机器提高整个消费队列服务的性能。\n通过将同一个topic中的不同partition分布在不同的broker上，再将多个broker构成一个kafka集群，实现硬件能力的扩展，提高kafka的处理速度。\n实现消息队列的高可用 解决单个broker宕机：一主多从 对每个partition，创建一个主节点，多个从节点，主节点负责读写，从节点只负责从主节点拉取数据、作数据备份。当某个broker宕机后，重新选取partition作为主节点。\n解决所有broker宕机：数据持久化与过期策略 如果数据都存储在内存中，当所有broker都宕机后未消费的消息将丢失，通过持久化并重启服务可实现服务宕机后的数据恢复。数据不断写入磁盘将会导致磁盘空间占满，需要一种过期策略剔除过期数据。\nKafka基本操作 ","date":"2025-01-27T00:28:09+08:00","image":"http://localhost:1313/p/kafka-introduction/cover_hu7829655988767931506.png","permalink":"http://localhost:1313/p/kafka-introduction/","title":"Kafka Introduction"},{"content":"git版本控制的方式 两种版本控制方式 基于差异的版本控制（delta-based） 这类版本控制将存储信息看作一组基本文件和每个文件随时间逐步积累的差异\n基于快照的版本控制 这类版本控制将存储信息看作对小型文件系统的一系列快照，在git中，每当提交更新或者保存项目状态时，就会基本上对当时的全部文件创建一个快照保存并保存这个快照的索引。\ngit环境配置 基本命令 设置全局配置\n1 git config --global config：表示配置git \u0026ndash;global：表示全局配置 设置用户名\n1 git config --global user.name \u0026#34;用户名\u0026#34; 设置邮箱\n1 git config --global user.email \u0026#34;邮箱\u0026#34; 用户名和邮箱是这台机器上git的唯一标志\n获取git仓库 本地仓库的创建和初始化 在已存在目录中创建和初始化 进入目录\n1 cd 目录名 初始化当前目录\n1 git init 执行git init目录后出现如下结果：\n1 2 3 4 5 6 7 8 9 10 11 zhaoyifeng@MacBook-Air-6 test % git init 提示：使用 \u0026#39;master\u0026#39; 作为初始分支的名称。这个默认分支名称可能会更改。要在新仓库中 提示：配置使用初始分支名，并消除这条警告，请执行： 提示： 提示：\tgit config --global init.defaultBranch \u0026lt;名称\u0026gt; 提示： 提示：除了 \u0026#39;master\u0026#39; 之外，通常选定的名字有 \u0026#39;main\u0026#39;、\u0026#39;trunk\u0026#39; 和 \u0026#39;development\u0026#39;。 提示：可以通过以下命令重命名刚创建的分支： 提示： 提示：\tgit branch -m \u0026lt;name\u0026gt; 已初始化空的 Git 仓库于 /Users/zhaoyifeng/Documents/LocalRepository/test/.git/ 查看仓库中的文件夹：\n1 2 zhaoyifeng@MacBook-Air-6 test % ls -ah .\t..\t.git .git文件夹默认处于隐藏状态，需要添加-ah参数才能查看所有文件\n查看.git文件夹中的内容\n1 2 3 zhaoyifeng@MacBook-Air-6 test % cd .git zhaoyifeng@MacBook-Air-6 .git % ls -ah .\t..\tHEAD\tconfig\tdescription\thooks\tinfo\tobjects\trefs 文件夹 作用 hooks 包含客户端或服务端的勾子脚本 info 保护一个全局性排除文件 logs 保存日志信息 objects 存储所有数据内容 refs 存储指向数据的提交对象的指针 config 包含项目特有的配置选项 description 用来显示对仓库的描述 HEAD 指示目前被检出的分支 index 保存暂存区信息 git中的工作区、暂存区、版本库和仓库中文件夹的对应关系 git中的区域 文件夹 工作区 项目目录 版本库 .git文件夹，用来存放代码及历史版本 暂存区 .git下的index文件，用来存储临时文件（只是在index文件中添加一条操作记录，并没有将内容存放到index文件中） 克隆现有的仓库 git克隆命令：git clone \u0026lt;url\u0026gt; name 会将远程仓库中的项目克隆到当前目录，然后初始化该项目，并进行add和commit git中的文件状态 未跟踪\n默认情况下，git仓库（执行git init命令的文件夹）下的文件处于未跟踪的状态，git无法对区进行跟踪管理。通过add命令可以将其由未跟踪变为已跟踪状态。\n已跟踪 添加到git仓库管理中的文件处于已跟踪的状态，git可以对其进行跟踪管理。已跟踪状态可以细分为：\n已暂存（Staged）：通过add命令将文件添加到暂存区后文件将处于Staged状态。\n已修改（Modified）：修改了已跟踪的文件后，将处于Modified状态\n未暂存（Committed）：将暂存区中的文件使用commit命令提交到git仓库后将处于Modified状态。\n本地仓库的操作命令 创建本地仓库\n创建一个空文件夹 进入该文件夹执行git init命令 添加文件到本地仓库\n在创建的文件夹中新建一个文件 使用git add xxx.xx命令将工作区中的文件添加到暂存区，文件状态由未跟踪变为已跟踪。 1 2 3 zhaoyifeng@MacBook-Air-6 test % vim test.txt zhaoyifeng@MacBook-Air-6 test % git add test.txt 版本库只能跟踪和管理文本文件，视频、图片等文件虽然可由git管理，但git只能记录其大小而无法记录具体修改的内容。 git add .将所有文件添加到暂存区。 取消暂存：git reset HEAD 文件名：取消暂存某一文件 使git commit -m \u0026quot;xxxx\u0026quot;将暂存区中的内容提交到本地仓库，-m后面的参数是本次提交的描述 1 2 3 4 zhaoyifeng@MacBook-Air-6 test % git commit -m \u0026#34;第一次提交\u0026#34; [master（根提交） f9de3df] 第一次提交 1 file changed, 1 insertion(+) create mode 100644 test.txt 使用git commit -m -a进行先暂存再提交 在工作目录中回退到最近一次提交的版本：git checkout -- \u0026lt;file\u0026gt; 修改commit的注释 执行如下命令\n1 git commit --amend 进入编辑器，修改注释信息\n修改后输入 control + o 然后输入输入回车进行写入\n退出编译器\n忽略文件 新建.gitignore文件，在里面添加需要忽略的文件\n查看历史提交记录和当前状态 执行git status命令查看状态，使用git status -s或git status --short查看简短的状态。\n1 2 3 4 zhaoyifeng@MacBook-Air-6 test % git status 位于分支 master 无文件要提交，干净的工作区 zhaoyifeng@MacBook-Air-6 test % 执行git log查看历史记录\n1 2 3 4 5 zhaoyifeng@MacBook-Air-6 test % git log commit bbf9be55393f4aaeb85909b9b4071973d21a2d50 (HEAD -\u0026gt; master) Author: zhaoyifeng \u0026lt;zhaoyifeng@lixiang.com\u0026gt; Date: Wed Jul 5 17:14:36 2023 +0800 The first time submit commit后面的字符串是这次提交的ID，（HEAD -\u0026gt; master)表示当前提交到了主分支，HEAD是一个指针\nAuthor后面提交用户的信息\nDate是提交时间\n最后一行是提交的描述信息\n查看差异\ngit diff：查看尚未暂存的文件进行了那些修改 git diff -- staged：对比已暂存文件和最后一次提交文件的差异 git中的分支 分支的本质 分支的本质：指向commit对象的可变指针（也可理解为执行数据快照的指针）\ncommit对象：每次提交时都会保存一个commit对象，，包含指向暂存内容快照的指针、本次提交的作者等相关附属信息、零个或多个指向该提交对象的父对象指针：首次提交是没有直接祖先的，普通提交有一个祖先，由两个或多个分支合并产生的提交则有多个祖先。\ngit分支：指向commit对象的指针。git会默认创建一个master分支，在每次提交时都会自动向前移动。\n创建分支：本质上就是创建一个指针，git branch testing新建一个分支指针指向当前commit对象。也就是HEAD指针指向的分支指向的commit对象。\nHEAD指针：指向当前所在的分支（HEAD不可直接指向commit对象）\n切换分支：改变HEAD指向的分支。git checkout testing切换到testing分支。\n当你切换分支的时候，Git 会重置你的工作目录，使其看起来像回到了你在那个分支上最后一次提交的样子。 Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样。\n每提交一次后，HEAD都会随着当前分支一起移动。（HEAD指向的是分支指针，提交时分支指针不变，改变的只是分支指针指向的对象。）执行：\n1 2 vim test rb git commit -a -m \u0026#39;made a change\u0026#39; 得到如下结果： 切换到一个分支时会将工作目录中的内容加载为该分支指向的快照中的内容，这会导致原来的工作目录中的内容丢失。\n分支分叉：如果切换到master分支并在修改后进行提交那就会产生分支的分叉。\n1 2 3 git checkout master vim test rb git commit -a -m \u0026#39;made other change\u0026#39; 分支的合并：\n未分叉分支的合并\n执行如下命令：\n1 2 3 4 5 6 $ git checkout master $ git merge hotfix Updating f42c576..3a0874c Fast forward README | 1 - 1 files changed, 0 insertions(+), 1 deletions(-) 可以发现出现了Fast forward也就是快进，这是因为要合并的分支在master的上游，只需要把master指向hotfix指向的commit对象即可。\n分叉分支的合并 合并如图所示的分支，将iss53合并回master，执行如下命令\n1 2 git checkout master git merge iss53 由于master指向的commit节点（C4）不是iss53指向的commit节点（C5）的直接祖先，因此会进行C4、C5和二者最近的共同祖先（C2）三个节点的简单三方合并的到一个新的简单快照，然后创建一个行的commit对象（C6）指向这个简单快照，然后master指向C6。\n三种不同的合并方式\ngit merge \u0026ndash;ff(fast-forward): 如果能快进则快进分支即移动指针\ngit merge \u0026ndash;no-ff(no-fast-forword): 即使能快进也会创建一个新的commit(内容和被合并分支的commit相同)\ngit merge \u0026ndash;squash: 将被合并节点的修改的内容（保存删除操作）加载到工作区和暂存区，等待一次新的提交\n合并时发生冲突：如果不同分支修改了同一部分，那合并时可能发生冲突。\n1 2 3 4 git merge iss53 Auto-merging index.html CONFLICT (content): Merge conflict in index.html Automatic merge failed; fix conflicts and then commit the result. git作了合并但未提交，它会停下来等待解决冲突。打开发生冲突的文件index.html：\n1 2 3 4 5 6 7 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD:index.html \u0026lt;div id=\u0026#34;footer\u0026#34;\u0026gt;contact : email.support@github.com\u0026lt;/div\u0026gt; ======= \u0026lt;div id=\u0026#34;footer\u0026#34;\u0026gt; please contact us at support@github.com \u0026lt;/div\u0026gt; \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; iss53:index.html =======上面是当前分支文件中的内容，下面是iss53分支的内容。手动解决冲突，然后执行git add index.html，一旦进入暂存区就代表冲突已解决。再执行git commit。\n删除分支：git branch -d 分支名，删除指定的分支。\n分支的管理 查看当前有哪些分支，其中*表示当前分支即HEAD指向的分支git branch\n1 2 3 zhaoyifeng@MacBook-Air-6 test % git branch * master testing 查看分支最后一次提交的信息git branch -v\n1 2 3 zhaoyifeng@MacBook-Air-6 test % git branch -v * master e13db42 Merge branch \u0026#39;testing\u0026#39; testing ad69ccd testing第四次提交 查看已合并到当前分支的分支：git branch --merged\n查看未合并到当前分支的分支：git branch --no-merged\n远程分支\n远程仓库的添加与查看\n添加远程仓库，url是远程仓库的地址，shorname是给url对应的远程仓库的命名。执行git clone url后会自动添加一个远程仓库并将其命名为origin，并且克隆这个远程仓库到本地。\n1 git remote add \u0026lt;shortname\u0026gt; \u0026lt;url\u0026gt;\t查看远程仓库\n1 2 zhaoyifeng@MacBook-Air-6 mytest % git remote origin 查看远程仓库和对应的URL，fetch表示拉取的链接，push表示推送的链接。\n1 2 3 zhaoyifeng@MacBook-Air-6 mytest % git remote -v origin\thttps://gitee.com/zhao-jufeng/mytest/ (fetch) origin\thttps://gitee.com/zhao-jufeng/mytest/ (push) 查看某个远程仓库的具体信息\n1 2 3 4 5 6 7 8 9 10 11 12 zhaoyifeng@MacBook-Air-6 mytest % git remote show origin * 远程 origin 获取地址：https://gitee.com/zhao-jufeng/mytest/ 推送地址：https://gitee.com/zhao-jufeng/mytest/ HEAD 分支：master 远程分支： dev 已跟踪 master 已跟踪 为 \u0026#39;git pull\u0026#39; 配置的本地分支：ƒ master 与远程 master 合并 为 \u0026#39;git push\u0026#39; 配置的本地引用： master 推送至 master (最新) 远程分支的查看：远程分支是存储在本地对应着远程数据库中分支的分支。\ngit branch：只能查看本地分支\ngit branch -r：查看远程分支\n远程仓库含有master和dev分支，执行git clone https://gitee.com/zhao-jufeng/mytest/命令后执行git branch -r可以得到： zhaoyifeng@MacBook-Air-6 mytest % git branch -r origin/HEAD -\u0026gt; origin/master origin/dev origin/master 可以看到有两个远程分支，origin是远程仓库的名字，执行clone命令时默命名为origin。需要注意的是，这些分支也存储在本地，与远程仓库作一一映射。\n执行tree .git查看.git的目录结构：\n``` zhaoyifeng@MacBook-Air-6 mytest % tree .git .git ├── HEAD ├── config ├── description ├── hooks │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── fsmonitor-watchman.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── pre-merge-commit.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ ├── pre-receive.sample │ ├── prepare-commit-msg.sample │ ├── push-to-checkout.sample │ ├── sendemail-validate.sample │ └── update.sample ├── index ├── info │ └── exclude ├── logs │ ├── HEAD │ └── refs │ ├── heads │ │ └── master │ └── remotes │ └── origin │ └── HEAD ├── objects │ ├── info │ └── pack │ ├── pack-d93bb5ea2faba296524bc440149ae8b102f490cf.idx │ ├── pack-d93bb5ea2faba296524bc440149ae8b102f490cf.pack │ └── pack-d93bb5ea2faba296524bc440149ae8b102f490cf.rev ├── packed-refs └── refs ├── heads │ └── master ├── remotes │ └── origin │ └── HEAD └── tags ``` 远程的refs中的内容被压缩到了packed-refs中，查看其内容可以看到两个远程分支。 cat .git/packed-refs # pack-refs with: peeled fully-peeled sorted 7eb1322ce1fa2104ac76d996c08eb1a861860cc1 refs/remotes/origin/dev 7eb1322ce1fa2104ac76d996c08eb1a861860cc1 refs/remotes/origin/master 如果refs中含有远程分支，则该分支是最新的，packed-refs对远程分支的压缩有延迟。 执行git log可以查看历史，master, origin/master, origin/dev, origin/HEAD都指向了一个commit对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 zhaoyifeng@MacBook-Air-6 mytest % git log commit 7eb1322ce1fa2104ac76d996c08eb1a861860cc1 (HEAD -\u0026gt; master, origin/master, origin/dev, origin/HEAD) Author: 赵已峰 \u0026lt;zhaoyifeng@lixiang.com\u0026gt; Date: Fri Jul 7 01:25:14 2023 +0000 add test.txt. Signed-off-by: 赵已峰 \u0026lt;zhaoyifeng@lixiang.com\u0026gt; commit d6ce159ed51c87cd4e7531dfbbeb6015e5c22f1f Author: 赵已峰 \u0026lt;zhaoyifeng@lixiang.com\u0026gt; Date: Fri Jul 7 01:24:38 2023 +0000 Initial commit 同步远程仓库中的分支到本地：在远程分支（本地存储的远程仓库的分支并不是远程仓库中的分支）上修改后提交或者执行merge命令不会移动远程分支，只有通过git fetch或者git pull才会改变远程分支。这是为了保持远程分支和远程仓库中的分支的对应关系，避免在本地对远程分支进行修改。\ngit fetch [remote-name]：从远程仓库中拉取本地仓库没有的数据，这个操作会移动远程分支。\n1 2 3 4 5 6 7 8 zhaoyifeng@MacBook-Air-6 mytest % git fetch remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0 展开对象中: 100% (3/3), 967 字节 | 193.00 KiB/s, 完成. 来自 https://gitee.com/zhao-jufeng/mytest 7eb1322..f20bd41 master -\u0026gt; origin/master git pull ：git fetch和git merge命名的组合\n1 git pull 远程仓库名 远程仓库分支名:本地分支名 拉取远程仓库中的分支在与本地分支merge（需要注意的是这会拉取远程仓库中的所有分支） 如何入当前分支合并则可以省略本地分支名，简写为：\n1 git pull 远程仓库名 远程仓库分支名 删除远程分支：\n删除远程仓库中的分支再查看会出现如下提示：\n1 2 3 4 5 6 7 8 9 10 11 12 zhaoyifeng@MacBook-Air-6 mytest % git remote show origin * 远程 origin 获取地址：https://gitee.com/zhao-jufeng/mytest/ 推送地址：https://gitee.com/zhao-jufeng/mytest/ HEAD 分支：master 远程分支： master 已跟踪 refs/remotes/origin/dev 已过期（使用 \u0026#39;git remote prune\u0026#39; 来移除） 为 \u0026#39;git pull\u0026#39; 配置的本地分支： master 与远程 master 合并 为 \u0026#39;git push\u0026#39; 配置的本地引用： master 推送至 master (本地已过时) 提示远程分支已过期，建议删除。执行如下命名删除：\n1 2 3 4 zhaoyifeng@MacBook-Air-6 mytest % git remote prune origin 修剪 origin URL：https://gitee.com/zhao-jufeng/mytest/ * [已删除] origin/dev 或者git fetch --prune先删远程仓库中没有的本地远程分支，然后再拉取远程仓库中的数据。\n本地仓库同步到远程仓库\ngit push 远程仓库名 本地分支名:远程仓库中的分支名：用本地仓库中的分支更新远程仓库的分支，这会让远程仓库的分支直接指向本地仓库的分支指向的commit，此外，与远程仓库中对应的远程分支也会指向本地分支指向的commit。注意，这并不要本地仓库中有远程仓库中对应的远程分支。\n如果本地分支名与远程仓库中的分支名相同，则可以简写为git push 远程仓库名 分支名\n跟踪分支：执行git push命令时需要同指定远程仓库名、本地分支名和远程分支名，而跟踪分支则可简化这个操作。\n跟踪分支：本地分支和某个远程分支建立联系后那这个本地分支就变成一个跟踪分支。在跟踪分支上执行git push和git pull命令时无需指定远程仓库名、本地分支名和远程分支名。\n跟踪分支的创建\n在远程分支上创建分支时指定其为远程分支（建的本地分支名与远程分支名相同）：$ git checkout --track 远程仓库名/远程分支名\n在远程分支上创建分支时指定其为远程分支（指定本地分支名）：git checkout -b 本地分支名 远程仓库名/远程分支名\n指定已有的本地分支为莫哥远程分支的跟踪分支：git branch -u 远程仓库名/远程分支名\ngit中的标签 什么是标签 标签的本质：一个指向commit对象的指针，类似于分支，但标签是一个静态指针，不会移动。 标签的作用：标记一个重要的commit。 打标签 给当前分支指向的commit打标签\n轻量标签：git tag 标签名 附注标签：git tag -a 标签名 -m \u0026quot;描述信息\u0026quot;，相比轻量标签，附注标签可以添加描述信息 给某一次commit打标签：只需要在上面两种打标签的方式最后面添加要打标签的commit的Hash值即可\n查看标签\n查看有哪些标签git tag 查看某一条标签的信息git show 标签名 ","date":"2025-01-03T22:04:00Z","image":"http://localhost:1313/p/git-introduction/cover_hu12240342566781648665.png","permalink":"http://localhost:1313/p/git-introduction/","title":"Git Introduction"},{"content":"","date":"2025-08-06T19:45:42+08:00","permalink":"http://localhost:1313/p/mybatis-plus/","title":"Mybatis Plus"},{"content":"待迁移数据的读写类型 写入类型 外部数据源写入 数据库中的多张表的数据源只取自外部，库内表数据写入不依赖其余表结构。 内部数据源写入 数据库中的多张表的数据源除取自外部，内部表与表之间也存在数据写入依赖。 读取类型 只读 读写 内部读写 外部读写 数据迁移方案 停机迁移 不停机迁移 数据迁移方案的利与弊 ","date":"2025-06-23T23:26:52+08:00","image":"http://localhost:1313/p/data-migrate/cover_hu320539778546803544.png","permalink":"http://localhost:1313/p/data-migrate/","title":"Data Migrate"},{"content":"mybatisplus SQL执行流程 服务启动时通过自动配置类创建MybatisSqlSessionFactoryBean mybatis-plus-boot-starter包提供了MybatisPlusAutoConfiguration自动配置类，该自动配置类创建了MybatisSqlSessionFactoryBean对象并交由Spring管理，在创建MybatisSqlSessionFactoryBean时，sqlSessionFactory方法设置了DataScoure对象。自动配置类需要满足以下几个条件才会创建MybatisSqlSessionFactoryBean：\nMybatisPlusAutoConfiguration上的@ConditionalOnSingleCandidate指定了：被Spring管理的只有一个DataSource对象或者多个DataSource对指定了优先级（如通过@Primary注解指定） sqlSessionFactory方法上@ConditionalOnMissingBean指定了：只有在不存在SqlSessionFactory时才会创建MybatisSqlSessionFactoryBean对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Configuration(proxyBeanMethods = false) @ConditionalOnClass({SqlSessionFactory.class, SqlSessionFactoryBean.class}) @ConditionalOnSingleCandidate(DataSource.class) @EnableConfigurationProperties(MybatisPlusProperties.class) @AutoConfigureAfter({DataSourceAutoConfiguration.class, MybatisPlusLanguageDriverAutoConfiguration.class}) public class MybatisPlusAutoConfiguration implements InitializingBean { @Bean @ConditionalOnMissingBean public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception { // TODO 使用 MybatisSqlSessionFactoryBean 而不是 SqlSessionFactoryBean MybatisSqlSessionFactoryBean factory = new MybatisSqlSessionFactoryBean(); factory.setDataSource(dataSource); ..... } } Spring对事务进行代理 执行Mybatisplus DML语句前，Spring对要执行的方法（加了@Transactiontional注解）进行代理，代理执行的逻辑在TransactionAspectSupport中的invokeWithinTransaction方法中。整体调用流程如下\nTransactionInterceptor#invoke -\u0026gt; TransactionAspectSupport#invokeWithinTransaction执行开启事务、执行业务逻辑、提交事务三个步骤。\n开启事务 TransactionAspectSupport#invokeWithinTransaction -\u0026gt; determineTransactionManager TransactionAspectSupport#determineTransactionManager -\u0026gt; createTransactionIfNecessary TransactionAspectSupport#createTransactionIfNecessary -\u0026gt; AbstractPlatformTransactionManager#getTransaction，getTransaction方法先尝试获取事务再开启事务： 获取事务 AbstractPlatformTransactionManager#getTransaction -\u0026gt; DataSourceTransactionManager#doGetTransaction（doGetTransaction是个抽象方法，具体逻辑由实现类提供，我们在这里只讨论DataSourceTransactionManager的实现逻辑） DataSourceTransactionManager#doGetTransaction，该方法做下如下操作： 创建DataSourceTransactionObject对象 TransactionSynchronizationManager.getResource方法获取DataSourceTransactionManager中dataScoure对象绑定的ConnectionHolder对象（用来存储connection对象）。TransactionSynchronizationManager中维护了一个ThreadLocal属性resources，这是一个以dataScoure对象为key、ConnectionHolder对象为值的Map。TransactionSynchronizationManager用来管理每个线程中和dataScoure对象绑定的connection对象。 将上一步获取的ConnectionHolder设置到DataSourceTransactionObject中 开启事务 AbstractPlatformTransactionManager#getTransactio -\u0026gt; DataSourceTransactionManager#startTransaction DataSourceTransactionManager#startTransactionn -\u0026gt; doBegin方法，实现如下操作（DataSourceTransactionManager#doGetTransaction对象返回的DataSourceTransactionObject中的ConnectionHolder为空时执行该步骤）： 通过DataSourceTransactionManager中dataScoure对象获取connection 将connection包装为ConnectionHolder对象 通过TransactionSynchronizationManager.bindResource将ConnectionHolder对象和connection对象绑定并设置上面提到的TransactionSynchronizationManager中的ThreadLocal属性resources中 执行业务逻辑 TransactionAspectSupport#invokeWithinTransaction执行被代理方法，mybatisplus中的方法也会在在此被执行，具体流程我们方法下一个部分讨论。 提交事务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 @SuppressWarnings(\u0026#34;serial\u0026#34;) public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable { @Override @Nullable public Object invoke(MethodInvocation invocation) throws Throwable { // Work out the target class: may be {@code null}. // The TransactionAttributeSource should be passed the target class // as well as the method, which may be from an interface. Class\u0026lt;?\u0026gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // Adapt to TransactionAspectSupport\u0026#39;s invokeWithinTransaction... return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed); } } public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean { @Nullable protected Object invokeWithinTransaction(Method method, @Nullable Class\u0026lt;?\u0026gt; targetClass, final InvocationCallback invocation) throws Throwable { // If the transaction attribute is null, the method is non-transactional. TransactionAttributeSource tas = getTransactionAttributeSource(); final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); final TransactionManager tm = determineTransactionManager(txAttr); ........ // 响应式事务处理逻辑 PlatformTransactionManager ptm = asPlatformTransactionManager(tm); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(ptm instanceof CallbackPreferringPlatformTransactionManager)) { // Standard transaction demarcation with getTransaction and commit/rollback calls. TransactionInfo txInfo = createTransactionIfNecessary(ptm, txAttr, joinpointIdentification); Object retVal; try { // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. retVal = invocation.proceedWithInvocation(); } catch (Throwable ex) { // target invocation exception completeTransactionAfterThrowing(txInfo, ex); throw ex; } finally { cleanupTransactionInfo(txInfo); } if (retVal != null \u0026amp;\u0026amp; vavrPresent \u0026amp;\u0026amp; VavrDelegate.isVavrTry(retVal)) { // Set rollback-only in case of Vavr failure matching our rollback rules... TransactionStatus status = txInfo.getTransactionStatus(); if (status != null \u0026amp;\u0026amp; txAttr != null) { retVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status); } } commitTransactionAfterReturning(txInfo); return retVal; }else { ...... // 非回调事务处理逻辑 } protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) { ........... TransactionStatus status = null; if (txAttr != null) { if (tm != null) { status = tm.getTransaction(txAttr); } ....... } ........... } } public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable { @Override public final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException { ........................... Object transaction = doGetTransaction(); boolean debugEnabled = logger.isDebugEnabled(); // No existing transaction found -\u0026gt; check propagation behavior to find out how to proceed. if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) { ............. } else if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) { SuspendedResourcesHolder suspendedResources = suspend(null); ............... try { return startTransaction(def, transaction, debugEnabled, suspendedResources); } catch (RuntimeException | Error ex) { } } else { ......... } } /** * Start a new transaction. */ private TransactionStatus startTransaction(TransactionDefinition definition, Object transaction, boolean debugEnabled, @Nullable SuspendedResourcesHolder suspendedResources) { boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus( definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); doBegin(transaction, definition); prepareSynchronization(status, definition); return status; } } public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean { protected Object doGetTransaction() { DataSourceTransactionObject txObject = new DataSourceTransactionObject(); txObject.setSavepointAllowed(isNestedTransactionAllowed()); ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(obtainDataSource()); txObject.setConnectionHolder(conHolder, false); return txObject; } protected void doBegin(Object transaction, TransactionDefinition definition) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try { if (!txObject.hasConnectionHolder() || txObject.getConnectionHolder().isSynchronizedWithTransaction()) { Connection newCon = obtainDataSource().getConnection(); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Acquired Connection [\u0026#34; + newCon + \u0026#34;] for JDBC transaction\u0026#34;); } txObject.setConnectionHolder(new ConnectionHolder(newCon), true); } txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); txObject.setReadOnly(definition.isReadOnly()); // Switch to manual commit if necessary. This is very expensive in some JDBC drivers, // so we don\u0026#39;t want to do it unnecessarily (for example if we\u0026#39;ve explicitly // configured the connection pool to set it already). if (con.getAutoCommit()) { txObject.setMustRestoreAutoCommit(true); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Switching JDBC Connection [\u0026#34; + con + \u0026#34;] to manual commit\u0026#34;); } con.setAutoCommit(false); } prepareTransactionalConnection(con, definition); txObject.getConnectionHolder().setTransactionActive(true); int timeout = determineTimeout(definition); if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) { txObject.getConnectionHolder().setTimeoutInSeconds(timeout); } // Bind the connection holder to the thread. if (txObject.isNewConnectionHolder()) { TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder()); } } catch (Throwable ex) { if (txObject.isNewConnectionHolder()) { DataSourceUtils.releaseConnection(con, obtainDataSource()); txObject.setConnectionHolder(null, false); } throw new CannotCreateTransactionException(\u0026#34;Could not open JDBC Connection for transaction\u0026#34;, ex); } } } 执行mybatisplus DML与Select语句 以调用IService的saveBatch方法为例，其最初调用链路如下ServiceImpl#saveBatch -\u0026gt; ServiceImpl#executeBatch -\u0026gt; SqlHelper#executeBatch， 执行步骤如下：\n获取SqlSessionFactory\nSqlHelper#executeBatch调用sqlSessionFactory方法，sqlSessionFactory对象中持有DataSource对象的引用。\n调用上面一步获取的SqlSessionFactory的openSession方法（这里以DefaultSqlSessionFactory加以说明），需要注意的事这里的Transaction对象并不参与事务的执行，只是用来管理数据源，该方法执行了如下步骤：\n创建TransactionFactory对象 通过TransactionFactory对象创建Transaction对象，并传入从configure（SqlSessionFactory持有）对象中获取的dataScoure对象 创建Executor对象并传入Transaction对象 创建DefaultSqlSession对象并传入Executor对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\u0026#34;Error opening session. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } 调用SqlSession的insert方法\n调用链路SqlSession#insert -\u0026gt; SqlSession#update -\u0026gt; BaseExecutor#update -\u0026gt; BatchExecutor#doUpdate，BatchExecutor#doUpdate执行了如下步骤： 获取Connection，调用BaseExecutor#getConnection -\u0026gt; Transaction.getConnection -\u0026gt; SpringManagedTransaction.getConnection -\u0026gt; SpringManagedTransaction.openConnection -\u0026gt; DataSourceUtils.getConnection -\u0026gt; DataSourceUtils.doGetConnection，从下面的代码可知道如果当前数据源绑定了Connection则获取绑定的Connection，如果没有绑定则调用DataScoure对象的getConnection方法获取新的connection方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public static Connection doGetConnection(DataSource dataSource) throws SQLException { ....... ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource); if (conHolder != null \u0026amp;\u0026amp; (conHolder.hasConnection() || conHolder.isSynchronizedWithTransaction())) { conHolder.requested(); if (!conHolder.hasConnection()) { logger.debug(\u0026#34;Fetching resumed JDBC Connection from DataSource\u0026#34;); conHolder.setConnection(fetchConnection(dataSource)); } return conHolder.getConnection(); } // Else we either got no holder or an empty thread-bound holder here. logger.debug(\u0026#34;Fetching JDBC Connection from DataSource\u0026#34;); Connection con = fetchConnection(dataSource); ........ return con; } private static Connection fetchConnection(DataSource dataSource) throws SQLException { Connection con = dataSource.getConnection(); if (con == null) { throw new IllegalStateException(\u0026#34;DataSource returned null from getConnection(): \u0026#34; + dataSource); } return con; } 准备Statement，设置Connection为上一步获取的Connection 执行SQL语句 DataScoure：数据库链接的管理者 不论是在Spring事务还是mybatisplus执行SQL语句前获取connection，都会调用DataScoure#getConnection方法。如下，DataScoure只提供了两个获取connection方法，由此可知DataScoure最主要的功能就是进行Connection的管理。对DataSource的getConnection方法提供不同的实现可以提供不同的功能，最典型的莫过于连接池和动态数据源。\n1 2 3 4 5 6 public interface DataSource extends CommonDataSource, Wrapper { Connection getConnection() throws SQLException; Connection getConnection(String username, String password) throws SQLException; } 连接池 我们以HikariCP为例，先介绍其在SpringBoot项目中如何使用，再介绍如何通过其获取Connection\nSpringBoot集成HikariCP\nyaml配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 spring: datasource: type: com.zaxxer.hikari.HikariDataSource url: jdbc:mysql://localhost:3306/test?useSSL=false username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver hikari: pool-name: MyHikariCP minimum-idle: 5 maximum-pool-size: 20 idle-timeout: 600000 max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 数据源属性类 1 2 3 4 5 6 7 8 9 10 11 @ConfigurationProperties(prefix = \u0026#34;spring.datasource\u0026#34;) public class DataSourceProperties implements BeanClassLoaderAware, InitializingBean { private ClassLoader classLoader; private String name; private boolean generateUniqueName = true; private Class\u0026lt;? extends DataSource\u0026gt; type; private String driverClassName; private String url; private String username; private String password; } Springboot自动配置\n当我们在yaml文件中指定了type: com.zaxxer.hikari.HikariDataSource满足了自动配置类@ConditionalOnProperty(name = \u0026quot;spring.datasource.type\u0026quot;, havingValue = \u0026quot;com.zaxxer.hikari.HikariDataSource\u0026quot;,matchIfMissing = true)的条件，创建HikariDataSource对象并交由Spring管理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 stract class DataSourceConfiguration { @Configuration(proxyBeanMethods = false) @ConditionalOnClass(HikariDataSource.class) @ConditionalOnMissingBean(DataSource.class) @ConditionalOnProperty(name = \u0026#34;spring.datasource.type\u0026#34;, havingValue = \u0026#34;com.zaxxer.hikari.HikariDataSource\u0026#34;, matchIfMissing = true) static class Hikari { @Bean @ConfigurationProperties(prefix = \u0026#34;spring.datasource.hikari\u0026#34;) HikariDataSource dataSource(DataSourceProperties properties) { HikariDataSource dataSource = createDataSource(properties, HikariDataSource.class); if (StringUtils.hasText(properties.getName())) { dataSource.setPoolName(properties.getName()); } return dataSource; } } } HikariDataSource实现数据库链接管理 在没有创建其他数据源的情况下，HikariDataSource会被注入Mybatisplus的MybatisSqlSessionFactoryBean并在执行SQL语句前被获取，HikariDataSource只需要重写getConnection方法就可实现对数据库连接的管理。如下代码，HikariDataSource获取数据库连接的功能最终委托给了HikariPool。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 public class HikariDataSource extends HikariConfig implements DataSource, Closeable { private static final Logger LOGGER = LoggerFactory.getLogger(HikariDataSource.class); private final AtomicBoolean isShutdown = new AtomicBoolean(); private final HikariPool fastPathPool; private volatile HikariPool pool; public HikariDataSource() { super(); fastPathPool = null; } public HikariDataSource(HikariConfig configuration) { configuration.validate(); configuration.copyStateTo(this); LOGGER.info(\u0026#34;{} - Starting...\u0026#34;, configuration.getPoolName()); pool = fastPathPool = new HikariPool(this); LOGGER.info(\u0026#34;{} - Start completed.\u0026#34;, configuration.getPoolName()); this.seal(); } @Override public Connection getConnection() throws SQLException { if (isClosed()) { throw new SQLException(\u0026#34;HikariDataSource \u0026#34; + this + \u0026#34; has been closed.\u0026#34;); } if (fastPathPool != null) { return fastPathPool.getConnection(); } // See http://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java HikariPool result = pool; if (result == null) { synchronized (this) { result = pool; if (result == null) { validate(); LOGGER.info(\u0026#34;{} - Starting...\u0026#34;, getPoolName()); try { pool = result = new HikariPool(this); this.seal(); } catch (PoolInitializationException pie) { if (pie.getCause() instanceof SQLException) { throw (SQLException) pie.getCause(); } else { throw pie; } } LOGGER.info(\u0026#34;{} - Start completed.\u0026#34;, getPoolName()); } } } return result.getConnection(); } } HikariPool核心代码如下，\n动态数据源 (待补充) 编译时动态 运行时动态 mybatisplus 执行 SQL时数据源问题总结 数据源DataScoure是一个管理数据库连接的对象，它与数据库连接是一对多的关联 mybatisplus的数据源对象取自SqlSessionFactory对象，在满足第一节Mybatisplus自动配置MybatisSqlSessionFactoryBean的条件下，mybatisplus获取的是优先级最高的（加了@Primary）DataScoure对象 指定事务管理器的数据源只会影响@Transactional注解绑定Datasource对象和Connection方法的逻辑，并不会影响mybatisplus实际获取的数据源（mybatisplus从SqlSessionFactory中取数据源） ","date":"2025-06-23T23:26:52+08:00","permalink":"http://localhost:1313/p/mybatisplus%E4%B8%8Edatasource/","title":"Mybatisplus与DataSource"}]